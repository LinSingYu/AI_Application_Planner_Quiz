<!DOCTYPE html>
<html lang="zh-Hant">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI 應用規劃師測驗</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Noto+Sans+TC:wght@400;500;700&display=swap');
        body {
            font-family: 'Noto Sans TC', sans-serif;
            background-color: #f1f5f9;
        }
        .fade-in {
            animation: fadeIn 0.4s ease-out;
        }
        @keyframes fadeIn {
            from { opacity: 0; transform: translateY(10px); }
            to { opacity: 1; transform: translateY(0); }
        }
        .option-btn:active:not(:disabled) {
            transform: scale(0.98);
        }
        /* 美化捲動條 */
        ::-webkit-scrollbar {
            width: 6px;
        }
        ::-webkit-scrollbar-thumb {
            background: #cbd5e1;
            border-radius: 10px;
        }
        .tab-active {
            border-bottom: 3px solid #4f46e5;
            color: #4f46e5;
        }
        .pulse-soft {
            animation: pulse 2s cubic-bezier(0.4, 0, 0.6, 1) infinite;
        }
        @keyframes pulse {
            0%, 100% { opacity: 1; }
            50% { opacity: .8; }
        }
    </style>
</head>
<body class="min-h-screen flex items-center justify-center p-4">

    <div id="app" class="bg-white w-full max-w-2xl rounded-3xl shadow-2xl overflow-hidden transition-all duration-300 relative border border-gray-100">
        <!-- 頂部標題列 -->
        <div class="bg-indigo-700 p-5 text-white">
            <div id="header-content" class="flex justify-between items-center px-2">
                <h1 id="main-title" class="text-lg font-bold tracking-wider flex items-center gap-2">
                    AI 應用規劃師測驗系統
                </h1>
                <div id="header-nav"></div>
            </div>
        </div>

        <!-- 視圖容器 -->
        <div id="view-container" class="p-6 md:p-8 min-h-[520px]">
            <!-- 內容動態插入 -->
        </div>

        <!-- 自訂對話框 (Modal) -->
        <div id="custom-modal" class="hidden fixed inset-0 bg-black/50 z-50 flex items-center justify-center p-4 backdrop-blur-sm">
            <div class="bg-white rounded-xl shadow-2xl w-full max-w-sm overflow-hidden fade-in">
                <div class="p-6">
                    <h3 id="modal-title" class="text-lg font-bold text-gray-800 mb-2">確認操作</h3>
                    <p id="modal-content" class="text-gray-600">您確定要執行此操作嗎？</p>
                </div>
                <div class="bg-gray-50 p-4 flex justify-end gap-3">
                    <button id="modal-cancel" class="px-4 py-2 text-gray-600 hover:bg-gray-200 rounded-lg transition font-medium">取消</button>
                    <button id="modal-confirm" class="px-4 py-2 bg-red-500 text-white hover:bg-red-600 rounded-lg transition font-medium">確定執行</button>
                </div>
            </div>
        </div>
    </div>

    <script>
        // 類別定義
        const categories = ["科目一", "科目二"];

        // 考試日期定義
        const EXAM_DATE = new Date('2026-03-21');
        // 每次考20題
        const MAX_QUESTIONS_PER_QUIZ = 20;

        
        // 題庫資料(增加 category 欄位)
        let questionBank = [
            {
                category: "科目一",
                question: "在人工智慧系統的決策流程中，關於「人在迴圈上(Human-over-the-loop)」的敘述，下列何者正確?",
                options: ["人類參與每一次的 AI 決策流程。", 
                          "人類對 AI 的運行進行日常監督，必要時可立即介入修正或干預。", 
                          "AI 的所有判斷皆須經過人類審核。", 
                          "人類完全不參與 AI 運作。"
                        ],
                correct: 1,
                explanation: "Human-over-the-loop 強調的是監督機制，人類平時進行監督，必要時介入。"
            },
            {
                category: "科目一",
                question: "在機器學習中，若希望抑制模型學習過於複雜的模式以提升泛化能力，通常會使用下列哪種技術?",
                options: ["特徵交叉(Feature Cross)", 
                            "正規化(Normalization)", 
                            "正則化(Regularization)", 
                            "獨熱編碼(One-hot Encoding)"
                        ],
                correct: 2,
                explanation: "正則化(如 L1、L2)透過在損失函數中加入懲罰項來控制模型複雜度。"
            },
            {
                category: "科目一",
                question: "下列哪一項任務最適合使用「非監督式學習(Unsupervised Learning)」來處理?",
                options: ["根據已標記的醫療影像診斷疾病。", "根據歷史房價數據預測未來房價。", "根據消費者的購買行為將其自動分群。", "透過獎勵機制訓練電腦玩圍棋。"],
                correct: 2,
                explanation: "非監督式學習不依賴標籤，其核心在於發掘資料內在結構，例如分群。"
            },
            {
                category: "科目一",
                question: "關於鑑別式 AI 與生成式 AI 的差異，下列敘述何者正確?",
                options: ["生成式 AI 的主要目標是進行分類與預測。", "鑑別式 AI 側重於學習數據的聯合分佈以產生新樣本。", "鑑別式 AI 專注於學習數據特徵與標籤之間的邊界。", "生成式 AI 不會產生新的數據，僅能分析現有數據。"],
                correct: 2,
                explanation: "鑑別式 AI 專注於尋找分類邊界；生成式 AI 則專注於學習數據分佈並生成新內容。"
            },
            {
                category: "科目一",
                question: "某公司建置了基於檢索增強生成(RAG)的系統，其主要優勢為何?",
                options: ["可以完全取代大型語言模型的推理能力。", "允許模型在回答時檢索外部數據源中的即時資訊，減少幻覺並提升準確度。", "可以大幅縮短模型的推論與回應時間。", "不需要任何外部資料庫即可運作。"],
                correct: 1,
                explanation: "RAG 結合了檢索與生成，能補足模型知識的時效性與準確性。但因增加了檢索步驟，通常會比單純問 AI 稍微慢一些"
            },
            {
                category: "科目二",
                question: "關於 No Code 與 Low Code 平台的敘述，下列何者最準確?",
                options: ["Low Code 平台完全不需要任何程式設計知識。", "No Code 平台主要面向非技術使用者，透過拖拉元件即可開發應用。", "兩者都只能開發非常簡單的靜態網頁。", "Low Code 平台無法與企業現有的 CRM 或 ERP 系統整合。"],
                correct: 1,
                explanation: "No Code 適合非技術人員快速開發；Low Code 則結合視覺化工具與少量程式碼，適合開發者進行更複雜或客製化的功能，且通常具備系統整合能力。"
            },
            {
                category: "科目二",
                question: "在使用生成式 AI 解決數學或邏輯問題時，為了提升準確度，可以使用下列哪種提示工程(Prompt Engineering)技巧?",
                options: [" 要求 AI 用一句話簡短回答。", "思維鏈(Chain-of-Thought)，要求 AI 詳細列出每一個思考步驟。",
                            "提高溫度參數(Temperature)以增加隨機性。", " 僅提供關鍵字，不給予完整指令。"
                ],
                correct: 1,
                explanation: "Chain-of-Thought(CoT)能引導模型逐步推理，有效提升解決複雜邏輯或數學問題的準確性"
            },
            {
                category: "科目二",
                question: "企業導入生成式 AI 時，若希望驗證技術在真實業務場景中的可行性與效果，通常會進行哪一個階段?",
                options: ["概念驗證(Proof of Concept, POC)。", "大規模全面部署。", "採購硬體設備。", "員工全面裁員"],
                correct: 0,
                explanation: "POC 階段是透過小規模實驗測試，評估模型效能與業務融合度，確認具有商業價值後才進行擴大導入。"
            },
            {
                category: "科目二",
                question: "生成式 AI 可能會產生看似合理但實際上錯誤或虛構的資訊，這種現象稱為什麼?",
                options: ["過度擬合(Overfitting)。","梯度消失(Vanishing Gradient)。","幻覺(Hallucination)。","數據漂移(Data Drift)。"],
                correct: 2,
                explanation: " 幻覺(Hallucination)是大型語言模型常見的風險，指模型生成內容通順但缺乏真實依據或完全虛構。"
            },
            {
                category: "科目二",
                question: "根據 AI 導入的風險管理，若企業將資料去識別化後再進行處理，主要是為了降低哪一類風險?",
                options: ["隱私與資安風險。","模型效能不足風險。","運算資源不足風險。","員工抗拒風險。"],
                correct: 0,
                explanation: "資料去識別化(Data Anonymization)或差分隱私技術，主要是為了保護敏感個資，符合隱私法規(如 GDPR)並降低資安風險。"
            },
            {
                category: "科目一",
                question: "在訓練機器學習模型時，為了防止模型過度學習訓練數據中的雜訊和細節，導致其在未見過的新數據上表現不佳的「過擬合」(Overfitting)現象，下列哪種策略是有效的?",
                options: ["在損失函數中添加懲罰項，如L1或L2正則化","僅使用訓練資料來評估模型最終的效能","延長模型的訓練時間，直到訓練誤差趨近於零","增加模型的複雜度，例如增加神經網路的層數"],
                correct: 0,
                explanation: "在損失函數中添加懲罰項，如L1或L2正則化，可以有效防止模型過度學習訓練數據中的雜訊和細節，從而提升其泛化能力。"
            },
            {
                category: "科目一",
                question: "一個AI模型被訓練來辨識一封電子郵件是「垃圾郵件」還是「非垃圾郵件」。這個模型的首要任務是學習這兩類郵件之間的決策邊界。此模型屬於哪一種類型的AI?",
                options: ["鑑別式AI","分辨型AI","強化式AI","生成式AI"],
                correct: 0,
                explanation: "鑑別式AI的核心是「判斷」，生成式AI的核心是「創造」，這準確描述了兩者的根本差異。"
            },
            {
                category: "科目一",
                question: "在處理影像辨識任務時，哪一種深度學習模型因其特殊的結構(如卷積層與池化層)，能夠有效提取影像中的空間特徵(如邊緣、紋理)，而被廣泛應用?",
                options: ["卷積神經網路(Convolutional Neural Networks, CNN)","循環神經網路(Recurrent Neural Networks, RNN)","生成對抗網路(Generative Adversarial Networks, GAN)","變分自編碼器(Variational Autoencoders, VAE)"],
                correct: 0,
                explanation: "CNN的卷積層和池化層結構使其特別擅長捕捉影像的局部特徵和空間層次結構，是影像辨識的經典模型。"
            },
            {
                category: "科目一",
                question: "在資料前處理階段，資料清洗是提升資料品質的關鍵步驟。下列何者是處理資料中「遺缺值(Missing Value)」的常見方法?",
                options: ["使用平均值、中位數或眾數進行填補","檢測並修正拼寫錯誤等錯誤值","使用主成分分析(PCA)進行降維","將所有資料進行Z-score標準化"],
                correct: 0,
                explanation: "根據資料的特性，使用統計量(如平均值、中位數)來填補遺缺值是一種直接且常用的資料清洗策略。"
            },
            {
                category: "科目一",
                question: "生成對抗網路(GAN)是由哪兩個相互競爭的神經網路組成的?",
                options: ["生成器(Generator)和判別器(Discriminator)","代理(Agent)和環境(Environment)","卷積層(Convolutional Layer)和池化層(Pooling Layer)","編碼器(Encoder)和解碼器(Decoder)"],
                correct: 0,
                explanation: "GAN的核心思想是生成器努力生成逼真數據來「欺騙」判別器，而判別器則努力區分真實與生成數據。"
            },
            {
                category: "科目一",
                question: "隨機森林(Random Forest)模型相較於單一的決策樹模型，其主要的優勢是什麼?",
                options: ["透過集成學習降低過擬合風險，提升穩定性","訓練速度更快","能夠處理非結構化數據，如音訊","模型的可解釋性更高"],
                correct: 0,
                explanation: "透過構建多棵在不同數據子集上訓練的決策樹並進行投票或平均，隨機森林能夠有效減少單一決策樹易受數據雜訊影響而過擬合的問題。"
            },
            {
                category: "科目一",
                question: "在資料處理與分析的架構中，ETL流程代表什麼?",
                options: ["萃取(Extract)、轉換(Transform)、載入(Load)","加密(Encrypt)、傳輸(Transmit)、紀錄(Log)","探索(Explore)、測試(Test)、載入(Load)","評估(Evaluate)、轉換(Transform)、學習(Learn)"],
                correct: 0,
                explanation: "ETL是資料倉儲和資料處理中的一個核心流程，指的是從來源萃取資料，進行清洗和轉換，最後載入到目標資料庫或系統中。"
            },
            {
                category: "科目一",
                question: "關於ETL（Extract-Transform-Load），下列敘述何者為正確？",
                options: ["T包括資料的清理與排序", "ETL的處理順序可以自由調整為TEL", "L表示將目標儲存庫經過反加密處理載入資料", "E表示將資料直接儲存至目標儲存庫"],
                correct: 0,
                explanation: ""
            },
            {
                category: "科目一",
                question: "循環神經網路(RNN)特別適合處理序列數據，但其訓練過程容易出現梯度消失或爆炸問題。下列哪一項是為了解決此問題而提出的改進版本?",
                options: ["長短期記憶網路(LSTM)","卷積神經網路(CNN)","生成對抗網路(GAN)","支援向量機(SVM)"],
                correct: 0,
                explanation: "LSTM透過引入遺忘門、輸入門和輸出門等門控機制，能有效捕捉長期依賴關係，並緩解梯度消失問題。"
            },
            {
                category: "科目一",
                question: "在機器學習流程中，為了避免模型在訓練資料上表現優異，但在測試資料上表現不佳的「過擬合」現象，下列何者是「不」常見的防範策略?",
                options: ["增加模型的層數與複雜度以捕捉更多特徵","透過隨機旋轉、翻轉等方式擴展訓練數據集(Data Augmentation)","在損失函數中添加L1或L2正則化(Regularization)","當模型在驗證集上的表現開始下降時，提早停止訓練(Early Stopping)"],
                correct: 0,
                explanation: "增加模型的複雜度反而更容易導致過擬合，因為模型有能力學習到訓練數據中更多的雜訊和不具泛化性的細節。"
            },
            {
                category: "科目一",
                question: "在機器學習的資料處理階段，使用 Z-score 標準化的主要目的是什麼?",
                options: ["將不同量級的特徵轉換到統一的範圍，消除尺度差異。","將所有數據映射到 0 到 1 的區間內。","減少資料集的維度以提高計算效率。","處理資料集中的遺缺值和重複值。"],
                correct: 0,
                explanation: "標準化的核心目的就是消除不同特徵因單位或量級不同所帶來的影響，使模型能公平對待所有特徵。"
            },
            {
                category: "科目一",
                question: "在非監督式學習中，K-均值聚類(K-Means)演算法的「K」值代表什麼意義?",
                options: ["使用者預先指定的群組(clusters)數量。","演算法需要迭代的總次數。","模型中每個群組的最小樣本數。","數據集中特徵(features)的數量。"],
                correct: 0,
                explanation: "在 K-Means 中，K 是一個超參數，代表使用者希望將數據集劃分為多少個群組。"
            },
            {
                category: "科目一",
                question: "下列何者最適合訓練電腦下圍棋、自動駕駛等動態重複地互動的問題? ",
                options: ["監督式學習(Supervised Learning)", "非監督式學習(Unsupervised Learning)", "半監督式學習(Semi-supervised Learning)", "強化學習(Reinforcement Learning)"],
                correct: 3,
                explanation: "強化學習(Reinforcement Learning, RL)是一種機器學習方法，"+
                "讓代理(Agent)透過與環境不斷互動，學習到一系列動作，以最大化累積獎勵。"+
                "這種學習方式非常適合用於訓練電腦在動態、複雜的環境中做出決策，例如下圍棋、自動駕駛等。"
            },
            {
                category: "科目一",
                question: "在分析一個地區的家庭年收入數據時，若數據中包含少數億萬富翁的極端高收入值，使用哪一個統計量來描述該地區的「典型」收入水平最能避免結果被扭曲?",
                options: ["中位數","平均數","眾數","標準差"],
                correct: 0,
                explanation: "中位數是將所有數據排序後取中間值，因此它不受極端值的影響，能更好地反映資料的中心趨勢。"
            },
            {
                category: "科目一",
                question: "在機器學習模型訓練前，對不同特徵(例如年齡範圍為18-65，月收入範圍為25,000-250,000)進行數據標準化或正規化的主要目的是什麼?",
                options: ["消除不同特徵之間的尺度差異，以提升模型訓練效果","填補資料集中缺失的值","減少資料集的維度以加快計算速度","將連續型數據轉換為離散的類別。"],
                correct: 0,
                explanation: "標準化或正規化可以消除不同特徵之間的尺度差異，使模型訓練更穩定且收斂更快。"
            },
            {
                category: "科目一",
                question: "某個AI系統被設計來玩一款迷宮遊戲，它透過不斷嘗試不同的路徑，並根據「找到出口」或「撞到牆壁」等回饋來學習最佳策略。這種學習方式最符合哪一種類型的機器學習?",
                options: ["強化學習(Reinforcement Learning)","非監督式學習","監督式學習","深度學習(Deep Learning)"],
                correct: 0,
                explanation: "強化學習(Reinforcement Learning, RL)是一種機器學習方法，讓代理(Agent)透過與環境不斷互動，學習到一系列動作，以最大化累積獎勵。這種學習方式非常適合用於訓練電腦在動態、複雜的環境中做出決策，例如下圍棋、自動駕駛等。"
            },
            {
                category: "科目一",
                question: "在深度學習領域中，哪一種神經網路模型因其能夠記憶序列中先前的資訊，特別適合處理和分析如文本翻譯、語音辨識等具有時間序列特性的資料?",
                options: ["循環神經網路(RNN)","卷積神經網路(CNN)","支援向量機(SVM)","生成對抗網路(GAN)"],
                correct: 0,
                explanation: "循環神經網路(RNN)的結構中存在循環連結，因其具有記憶功能，能處理序列數據並捕捉時間上的依賴關係，特別適合處理如文本翻譯、語音辨識等具有時間序列特性的任務。"
            },
            {
                category: "科目一",
                question: "關於鑑別式AI(Discriminative AI)與生成式AI(Generative AI)的主要目標，下列敘述何者最為貼切?",
                options: ["鑑別式AI學習數據的潛在分佈以創造新內容，生成式AI學習數據的決策邊界以進行分類。","兩者都專注於數據分類，但生成式AI的準確率通常更高。","鑑別式AI專注於學習如何區分不同類別的數據，而生成式AI專注於學習如何產生新的數據。","鑑別式AI只能處理結構化數據，而生成式AI專為非結構化數據設計。"],
                correct: 2,
                explanation: "鑑別式AI的核心是「判斷」，生成式AI的核心是「創造」，這準確描述了兩者的根本差異。"
            },
            {
                category: "科目一",
                question: "關於AI的定義，下列敘述何者較為正確？",
                options: ["AI僅限於深度學習技術","AI包括各種技術，例如機器學習、專家系統等","AI系統只能在學術研究中應用","AI無法應用於金融領域"],
                correct: 1, //B
                explanation: "人工智慧(AI)就像是一個龐大的拼圖，由許多不同的技術碎片組成。這些技術各司其職，共同構成了我們所理解的人工智慧。"
            },
            {
                category: "科目一",
                question: "為了提升AI系統的透明性，下列哪種措施是適當的？ ",
                options: ["不需對外揭露任何有關AI系統的資訊","規劃透過發布報告、技術文件或網站揭露AI系統的相關資訊","僅對內部員工進行透明性說明","將所有AI系統資訊保密"],
                correct: 1, //B
                explanation: "透過定期或不定期發佈AI系統於各決策環節的決策流程，有助於提昇 AI 系統的透明性。"
            },
            {
                category: "科目一",
                question: "下列何者不適合做為資料分布估計？",
                options: ["直方圖(Histogram)","散布圖(Scatter plot)","雷達圖(Radar chart)","四分位數(Quartile)"],
                correct: 2, //C
                explanation: "雷達圖有幾個限制，無法直觀呈現機率密度：雷達圖主要用於比較不同個體在多個維度上的表現，而非呈現數據在每個維度上的分布情況。要了解數據在某個維度上的集中程度、分散程度等，需要更適合的圖形，如直方圖。"
            },
            {
                category: "科目一",
                question: "K-Means 聚類算法中，K代表什麼？",
                options: ["數據集中特徵的數量","數據集中樣本的數量","所需劃分的群組數量","迭代次數"],
                correct: 2, //C
                explanation: "K 在 K-Means 演算法中代表我們希望將數據分為幾個群組。K 值的選擇會直接影響最終的聚類結果，因此是一個非常重要的參數。"
            },
            {
                category: "科目一",
                question: "深度學習模型中，下列哪一項通常用來降低過擬合問題？",
                options: ["增加訓練數據量","增加模型的複雜度","增加學習率","增加正則化項"],
                correct: 3, //D
                explanation: "過擬合指的是模型過度學習訓練數據中的雜訊或特徵，導致在測試集上表現不佳。正則化是一種在模型中加入額外項來懲罰複雜模型的方法，常見的正則化項有L1正則化和L2正則化。增加正則化項可以使模型變得更簡單，降低過擬合的風險，提高模型的泛化能力。 "
            },
            {
                category: "科目一",
                question: "生成式人工智慧最核心的能力是什麼？",
                options: ["從大量數據中學習", "執行複雜的數學計算", "生成新的、原創的內容", "控制機器人"],
                correct: 2, //C
                explanation: "生成式AI的最大特徵就是能夠生成全新的文本、圖像、音樂等內容。這與傳統的AI主要用於分析或預測已有數據不同。生成式 AI透過學習大量數據的模式，能產生出具有創造性的輸出。"
            },
            {
                category: "科目一",
                question: "下列哪項技術是生成式AI發展的重要基礎？",
                options: ["決策樹","神經網路","線性迴歸","貝氏分類"],
                correct: 1, //B
                explanation: "神經網路，尤其是深度學習模型，是生成式AI的基石。這些模型能夠學習數據中的複雜模式，並生成與訓練數據相似但又不完全相同的新的數據。其他選項如決策樹、線性迴歸和貝氏分類雖然也是機器學習的重要方法，但並不擅長生成新的內容。"
            },
            {
                category: "科目一",
                question: "關於AI，下列敘述何者較為正確？",
                options: ["AI僅限於深度學習技術","AI包括各種技術，例如機器學習、專家系統等","AI系統只能在學術研究中應用","AI無法應用於金融領域"],
                correct: 1, //B
                explanation: "AI是一個廣泛的領域，涵蓋了多種技術，包括但不限於機器學習、深度學習、專家系統、自然語言處理和計算機視覺等。它不僅限於深度學習，也不僅侷限於學術研究，且已成功應用於金融、醫療、製造等多個領域。"
            },
            {
                category: "科目一",
                question: "在 AI治理中，下列何者是國際合作的重要性？",
                options: ["統一AI發展標準","避免AI技術的濫用","促進AI技術的轉移","以上皆是"],
                correct: 3, //D
                explanation: "在AI治理中，國際合作的重要性包含多個方面，主要包括：統一AI發展標準，確保不同國家在技術應用上的一致性和互操作性。避免AI技術的濫用，透過跨國監管和政策協調減少倫理與安全風險。促進AI技術的轉移，幫助各國共享技術資源，縮小數位鴻溝。因此，以上選項都屬於國際合作的重要性。"
            },
            {
                category: "科目一",
                question: "關於K平均法(K-means)，下列敘述何者「不」正確？",
                options: ["希望找出k個互不交集的群集","不同的起始群集中心，可能會造成不同的分群結果","容易受雜訊與離群值(Outlier)影響其群集中心","可以處理類別型資料"],
                correct: 3,
                explanation: "K-means 演算法特性為隨機選取集群中心、依距離計算、各群質心為代表點、分割式分群、易受離群值影響、類別型資料集群方法。以類別型資料為例：「台北」減去「台中」等於多少？「紅色」和「藍色」的平方差是多少？在數學上，類別之間沒有自然的「距離」或「方向」概念"
            },
            {
                category: "科目一",
                question: "在品質管理中，若一產品的生產過程中標準差顯著偏大，通常意味著什麼？",
                options: ["資料點高度集中，產品質量穩定","生產過程波動大，產品品質不穩定","資料無法反映產品實際狀況 ","中位數數值高，品質良率較高"],
                correct: 1,
                explanation: "標準差越大表示數據分散程度越高，在品質管理中意味著產品或過程波動大，進而導致產品品質不穩定。"
            },
            // {
            //     category: "科目一",
            //     question: "下列何者「並非」K平均數(k-means)集群法的特點？ ",
            //     options: ["原理相對其他集群法較為複雜","可結合其他方法，使用上較為彈性 ","在特定情況下，能將集群的任務處理得足夠好",")不適合非球形、數據密度變化大或有離群數據的集群問題"],
            //     correct: 1,
            //     explanation: ""
            // },
            {
                category: "科目一",
                question: "驗證性資料分析(Confirmatory Data Analysis, CDA)與探索性資料分析(Exploratory Data Analysis, EDA)相比，主要著重於下列哪一項？",
                options: ["對資料進行初步描述和視覺化","驗證先前生成的假設並進行深入挖掘","排除資料中的極端值以提高準確性","探索數據中潛在的模式和異常"],
                correct: 1,
                explanation: "驗證性資料分析的重點在於檢驗先前所提出的假設，通常採用分類、分群、相關性分析或預測模型等方法進行深入分析。"
            },
            {
                category: "科目一",
                question: "以下哪種情況下，使用中位數來描述資料的集中趨勢最為合適？",
                options: ["一組考試成績，大部分學生分數集中在80分左右","一組房屋價格數據，其中包含少數豪宅的極端高價 ","一組產品銷售量數據，每個產品的銷量差異不大 ","一組學生身高數據，呈現出常態分布"],
                correct: 1,
                explanation: "平均數：易受極端值影響。當資料中有極端值時，平均數可能會偏離資料的中心趨勢。中位數：不受極端值影響。它能更準確地反映資料的中心趨勢，特別是在資料分布不對稱或有極端值的情況下。眾數：表示資料中出現頻率最高的數值。考試成績集中在 80 分左右： 資料分佈集中且對稱時，平均數與中位數會非常接近，通常使用「平均數」即可，因為它能納入所有學生的分數進行計算。銷售量差異不大： 當資料波動很小時，平均數能精確反映整體表現。學生身高呈現「常態分布」： 在常態分布(鐘形曲線)中，平均數、中位數和眾數三者會重合。此時通常優先選用「平均數」，因為它在數學統計上的應用更廣。"
            },
            {
                category: "科目一",
                question: "一組數據中，如果平均數小於中位數，那麼這組數據的分布可能是下列哪一種? ",
                options: ["對稱分布","正偏態分布","負偏態分布","無法判斷 "],
                correct: 2,
                explanation: "對稱分布：平均數、中位數和眾數通常會接近。正偏態分布：資料的尾巴向右邊延伸，平均數會大於中位數。負偏態分布：資料的尾巴向左邊延伸，平均數會小於中位數。 "
            },
            {
                category: "科目一",
                question: "當我們進行一次假設檢定，得到的p值為0.03，顯著性水準設定為0.05，以下哪一個敘述是正確的？",
                options: ["我們有97%的信心拒絕虛無假設","我們有95%的信心拒絕虛無假設","我們無法拒絕虛無假設","我們有5%的機率犯型一錯誤"],
                correct: 1,
                explanation: "p值為0.03表示，在虛無假設為真的情況下，觀察到目前數據或更極端數據的機率是3%。換句話說，如果虛無假設是正確的，那麼得到這樣的結果是非常罕見的。顯著性水準設定為0.05表示，我們願意接受5%的風險來拒絕一個實際為真的虛無假設(即Type-I Error)。 比較p值和顯著性水準：由於0.03 < 0.05，因此我們拒絕虛無假設。這意味著，我們有95%的信心認為，觀察到的結果並非偶然，而是支持對立假設。 "
            },
            {
                category: "科目一",
                question: "一組資料中，若平均數大於中位數，則這組資料的分布可能是下列哪一種？ ",
                options: ["對稱分布","負偏態分布","正偏態分布 ","無法判斷"],
                correct: 2,
                explanation: "對稱分布：平均數、中位數和眾數通常會接近；負偏態分布：資料的尾巴向左邊延伸，平均數會小於中位數；正偏態分布：資料的尾巴向右邊延伸，平均數會大於中位數。"
            },
            {
                category: "科目一",
                question: "下列哪一個敘述關於四分位距(IQR)是正確的？ ",
                options: ["四分位距會受到極端值的影響","四分位距代表資料中所有數據的分散程度","四分位距是第三四分位數與第一四分位數的差 ","四分位距與平均數一樣，容易受到極端值影響"],
                correct: 2,
                explanation: "四分位距(IQR)是第三四分位數(Q3)與第一四分位數(Q1)的差，它代表資料中間50%數據的分散程度，一般用於偏態或不規則分佈，像是薪資、房價、考試成績等有極端高分時，結果較不受極端值影響。舉例：調查某公司的薪資。如果老闆的月薪是 200 萬，而員工多在 4-6 萬之間，老闆的薪水會拉高「平均值」和「標準差」，讓人誤以為員工薪水落差極大。此時用 IQR 就能更真實反映出一般員工的薪資分布範圍。"
            },
            {
                category: "科目一",
                question: "以下哪一種情況最適合用眾數來描述資料的集中趨勢？",
                options: ["一組學生身高資料，呈現出常態分布","一組產品銷售量資料，其中一種產品的銷量遠高於其他產品","一組考試成績資料，大部分學生的分數集中在80分左右","一組房屋價格資料，其中包含少數豪宅的極端高價 "],
                correct: 1,
                explanation: "眾數代表資料中出現頻率最高的數值。當資料中有一個或幾個數值出現的頻率明顯高於其他數值時，眾數能較好地反映資料的集中趨勢。當一種產品的銷量遠高於其他產品時，這個產品的銷量就是眾數。這代表大多數的銷售額來自於這個產品，使用眾數能更直接地反映出最受歡迎的產品。 "
            },
            {
                category: "科目一",
                question: "機器學習的三個核心要素是什麼？",
                options: ["數據、模型、損失函數","訓練集、測試集、驗證集 ","特徵工程、優化演算法、正則化 ","超參數調整、模型選擇、數據處理"],
                correct: 0,
                explanation: "機器學習的三個核心要素分別是數據(Data)、模型(Model)和損失函數(Loss Function)，其中數據提供基礎，模型學習數據的規律，損失函數用於評估預測的準確性並指導模型優化。"
            },
            {
                category: "科目一",
                question: "下列哪一項屬於監督式學習的特點？ ",
                options: ["數據集中包含標記訊息","僅需探索數據內部的結構 ","使用代理與環境互動進行學習","不需要驗證集來調整參數"],
                correct: 0,
                explanation: "監督式學習依賴有標記的數據集，透過學習輸入與輸出之間的映射關係來進行預測或分類。不需要驗證集來調整參數是非監督式學習的特點；使用代理與環境互動進行學習是強化學習的特點。"
            },
            {
                category: "科目一",
                question: "機器學習模型過擬合的主要原因是什麼？",
                options: ["模型的複雜度不足","訓練數據樣本過多 ","模型過度學習數據中的雜訊","使用過於簡單的損失函數 "],
                correct: 2,
                explanation: "過擬合通常是由於模型學習了訓練數據中的雜訊或特定模式，導致模型對測試數據泛化能力不足。"
            },
            {
                category: "科目一",
                question: "交叉驗證的主要目的是什麼？",
                options: ["提高模型的訓練速度","驗證數據是否線性可分 ","減少模型的過擬合風險","測試模型的容錯能力"],
                correct: 2,
                explanation: "交叉驗證透過多次分割數據進行訓練和測試，有助於評估模型的穩健性並降低過擬合的可能性。"
            },
            {
                category: "科目一",
                question: "機器學習的梯度下降演算法主要用於什麼？",
                options: ["減少模型的計算複雜度","優化模型參數以最小化損失函數 ","減少數據中的雜訊干擾 ","增強數據特徵的表示能力"],
                correct: 1,
                explanation: "梯度下降演算法是一種優化方法，通常用於求解無約束最佳化問題的一階疊代最佳化算法，被用來求得可微函數的局部極小值，透過計算損失函數相對參數的偏導數，調整模型參數使損失函數值逐漸減小。"
            },
            {
                category: "科目一",
                question: "線性迴歸模型最適合解決哪種類型的問題？",
                options: ["圖像分類","銷售額預測 ","聚類分析 ","遊戲策略學習 "],
                correct: 1,
                explanation: "線性迴歸是一種典型的迴歸模型，用於解決輸出為連續值的問題，如預測銷售額或房價。"
            },
            {
                category: "科目一",
                question: "決策樹的最大優勢是什麼？",
                options: ["適合大規模數據的訓練 ","具有良好的可解釋性","不需要進行數據標準化","適用於圖像生成任務 "],
                correct: 1,
                explanation: "決策樹的分支結構清晰，便於直觀解釋，因此廣泛用於需要高可解釋性的任務，如醫學診斷或風險評估。"
            },
            {
                category: "科目一",
                question: "神經網路與傳統機器學習模型的主要區別是什麼？",
                options: ["神經網路無法處理非線性數據","神經網路透過多層結構學習複雜特徵","神經網路只適用於迴歸問題","神經網路不需要大量數據支持"],
                correct: 1,
                explanation: "神經網路具有多層結構，能夠從數據中提取高層次特徵，適合處理複雜的非線性問題，例如圖像分類和語音辨識。"
            },
            {
                category: "科目一",
                question: "下列關於生成對抗網路(GAN)的描述正確的是哪一項？",
                options: ["GAN僅用於分類問題","GAN由生成器和鑑別器組成","GAN的結果始終高度可解釋","GAN不能生成高品質的數據"],
                correct: 1,
                explanation: "生成對抗網路(GAN)由生成器和鑑別器組成，透過對抗學習生成高品質的數據，應用於圖像生成、文本生成等任務。"
            },
            {
                category: "科目一",
                question: "隨機森林(Random Forest)改進了單一決策樹的缺陷，主要透過什麼方法實現？",
                options: ["使用核函數映射高維空間","集成多棵隨機生成的決策樹並投票","增加模型參數以減少偏差","採用生成模型替代分類器"],
                correct: 1,
                explanation: "隨機森林是決策樹的集成演算法，透過構建多棵隨機決策樹並對其結果進行投票，有效降低了過擬合的風險。"
            },
            {
                category: "科目一",
                question: "某問題公司內部的經營數據分散在多個舊有系統，格式不一且難以管理，導致決策者無法取得一致的分析結果。問題：AI技術如何具體協助該公司改善資料管理困難？",
                options: ["透過資料整合、數據清洗和視覺化","增加資料的複雜性以提升分析深度","減少資料的收集以簡化管理","將資料分散儲存在更多地方以分散風險"],
                correct: 0,
                explanation: "AI技術可以透過整合多個來源的資料、清洗不一致的數據並提供視覺化工具，幫助企業建立統一且易於理解的數據視圖。"
            },
            {
                category: "科目一",
                question: "在處理一個包含使用者評論、產品圖片和銷售紀錄表格的資料庫時，這三種資料分別最貼切地對應到哪三種類型的資料結構?",
                options: ["非結構化資料、非結構化資料、結構化資料","半結構化資料、非結構化資料、結構化資料","結構化資料、半結構化資料、非結構化資料","非結構化資料、結構化資料、半結構化資料"],
                correct: 0,
                explanation: "使用者評論和圖片缺乏固定的格式，屬於非結構化資料；而銷售紀錄表格具有明確的行列定義，是典型的結構化資料。"
            },
            {
                category: "科目一",
                question: "某公司發現上季度的銷售額突然下降，分析師為了探究「為什麼會發生」，從總銷售額開始，逐層深入到地區、產品類別，最後到特定門市。這種分析方法屬於哪一種類型?",
                options: ["探索性分析","診斷性分析","預測性分析","敘述性分析"],
                correct: 1,
                explanation: "診斷性分析是用來探究問題發生的原因，透過深入分析數據找出導致異常的關鍵因素。"
            },
            {
                category: "科目一",
                question: "在訓練模型時，如果模型在訓練集表現極佳，但在測試集表現極差，這種現象稱為？",
                options: ["欠擬合(Underfitting)", "過度擬合(Overfitting)", "泛化成功", "數據偏誤"],
                correct: 1,
                explanation: "過度擬合是指模型學習了訓練集中的雜訊，導致對未見過的數據缺乏泛化能力。"
            },
            {
                category: "科目一",
                question: "下列何者為衡量分類模型「正確預測為正類別佔所有預測為正類別之比例」的指標？",
                options: ["準確率(Accuracy)", "召回率(Recall)", "精確率(Precision)", "F1 分數"],
                correct: 2,
                explanation: "精確率(Precision)計算的是預測為正向的樣本中，真正為正向的比例。"
            },
            {
                category: "科目一",
                question: "關於 AI 倫理中的「透明性」，下列敘述何者最正確？",
                options: ["AI 系統必須對外公開所有原始碼。", "AI 的決策過程應該在一定程度上可被解釋或追蹤。", "AI 系統不需要向用戶說明數據來源。", "AI 的開發成本必須透明化。"],
                correct: 1,
                explanation: "透明性強調系統的可解釋性，讓人類了解決策依據，而不一定是指公開所有技術細節。"
            },
            {
                category: "科目一",
                question: "「遷移學習(Transfer Learning)」的主要優點是什麼？",
                options: ["可以完全不需要任何數據", "利用已訓練模型的知識，減少新任務的訓練時間與數據量", "保證模型百分之百準確", "讓模型不需要任何運算資源"],
                correct: 1,
                explanation: "遷移學習利用在大規模數據集上預訓練過的模型，幫助在數據較少的小任務上取得更好效果。"
            },
            {
                category: "科目一",
                question: "神經網路中，負責將輸入信號轉換為輸出信號，決定神經元是否激發的函數稱為？",
                options: ["激勵函數(Activation Function)", "損失函數(Loss Function)", "優化函數", "線性函數"],
                correct: 0,
                explanation: "激勵函數(如 ReLU, Sigmoid)決定了神經元的非線性轉換與激發狀態。"
            },
            {
                category: "科目一",
                question: "透過與環境互動、獲得獎勵或懲罰來學習最佳策略的學習方式稱為？",
                options: ["監督式學習", "非監督式學習", "強化學習", "標註學習"],
                correct: 2,
                explanation: "強化學習的核心在於智能體(Agent)透過回饋(Reward)來優化其行為決策。"
            },
            {
                category: "科目一",
                question: "遞歸神經網路(RNN)最主要的特性是？",
                options: ["處理靜態影像", "處理序列型數據與具備記憶效應", "運算速度比 CNN 快", "不需要任何激活函數"],
                correct: 1,
                explanation: "RNN 具備循環結構，能夠處理時間序列或文字序列等具備前後關係的數據。"
            },
            {
                category: "科目一",
                question: "「自然語言處理(NLP)」的核心目標是什麼？",
                options: ["讓電腦學會畫畫", "讓電腦理解、詮釋及生成人類語言", "讓電腦預測天氣", "優化電腦硬體架構"],
                correct: 1,
                explanation: "NLP 專注於打破人類語言與電腦代碼之間的藩籬。"
            },
            {
                category: "科目一",
                question: "著名的「圖靈測試」主要是用來評估什麼？",
                options: ["電腦的運算速度", "電腦是否具備與人類等同的智能表現", "電腦的安全性", "程式碼的錯誤率"],
                correct: 1,
                explanation: "艾倫·圖靈提出的測試方法，旨在判斷機器是否表現出讓人無法區分的智能行為。"
            },
            {
                category: "科目一",
                question: "在訓練神經網路時，「倒傳遞(Backpropagation)」演算法的主要功能是？",
                options: ["增加數據量", "將預測結果輸出給用戶", "根據誤差計算梯度並更新神經網路中的權重", "初始化神經元參數"],
                correct: 2,
                explanation: "倒傳遞是訓練神經網路的核心，透過鏈鎖法則計算誤差對權重的影響(梯度)。"
            },
            {
                category: "科目一",
                question: "下列何者為常見的非線性激勵函數(Activation Function)？",
                options: ["ReLU", "y = ax + b", "均值函數", "單位矩陣"],
                correct: 0,
                explanation: "ReLU(Rectified Linear Unit)是目前深度學習中最廣泛使用的非線性激勵函數。"
            },
            {
                category: "科目一",
                question: "機器學習中的「偏差(Bias)」過高通常表示模型？",
                options: ["發生過度擬合", "過於複雜", "發生欠擬合(無法捕捉數據規律)", "運算資源不足"],
                correct: 2,
                explanation: "高偏差表示模型太過簡單，無法學習到數據的內在趨勢(欠擬合)。"
            },
            {
                category: "科目一",
                question: "由開發者在訓練前手動設定，而非由模型自動學習得出的參數稱為？",
                options: ["權重(Weights)", "偏置(Bias)", "超參數(Hyperparameters)", "特徵值"],
                correct: 2,
                explanation: "超參數(如學習率、迭代次數)需要人工調整，而權重是模型訓練中自動學習的參數。"
            },
            {
                category: "科目一",
                question: "「梯度下降法(Gradient Descent)」在模型訓練中的作用是？",
                options: ["增加模型複雜度", "尋找損失函數的最小值以優化權重", "產生合成數據", "數據特徵工程"],
                correct: 1,
                explanation: "梯度下降法是一種優化演算法，沿著梯度的反方向尋找最佳參數值。"
            },
            {
                category: "科目一",
                question: "損失函數(Loss Function)的主要用途是？",
                options: ["用來計算模型的預測值與真實值之間的差距", "用來清除髒數據", "用來加速 GPU 運算", "用來生成圖像"],
                correct: 0,
                explanation: "損失函數提供了一個量化的指標，讓模型知道目前的表現有多差，以便優化。"
            },
            {
                category: "科目一",
                question: "大型語言模型(LLM)如 GPT 系列，主要基於哪種基礎架構？",
                options: ["CNN", "RNN", "Transformer", "LSTM"],
                correct: 2,
                explanation: "鑑別式AI專注於學習數據的條件概率P(y|x)，主要用於分類或迴歸任務，而非生成數據。"
            },
            {
                category: "科目一",
                question: "下列何者為鑑別式AI的主要目標？",
                options: ["學習數據的生成過程", "生成類似真實數據的新樣本", "分類或迴歸數據", "創建多樣化的數據分佈"],
                correct: 2,
                explanation: "Transformer 架構中的注意力機制(Attention)是目前 LLM 發展的基石。"
            },
            {
                category: "科目一",
                question: "下列何者屬於生成式AI使用之模型？",
                options: ["支援向量機(SVM)", "邏輯迴歸(Logistic Regression)", "生成對抗網路(GAN)", "隨機森林(Random Forest)"],
                correct: 2,
                explanation: "生成對抗網路(GAN)是典型的生成式AI模型，專注於生成新數據，而其他選項均為鑑別式模型。"
            },
            {
                category: "科目一",
                question: "關於目前生成式AI的主要應用，不包括下列哪一項？",
                options: ["創建合成數據樣本", "模擬數據分佈", "分類醫學影像", "生成文本"],
                correct: 2,
                explanation: "生成式AI的核心應用包括生成合成數據、模擬分佈和生成文本，而分類醫學影像屬於鑑別式AI的應用範疇。"
            },
            {
                category: "科目一",
                question: "生成對抗網路(GAN)的兩個核心組件是什麼？",
                options: ["編碼器與解碼器", "分類器與生成器", "生成器與鑑別器", "訓練器與推斷器"],
                correct: 2,
                explanation: "GAN的兩個核心組件為生成器(Generator)和鑑別器(Discriminator)，生成器負責生成數據，鑑別器負責判斷數據真假。"
            },
            {
                category: "科目一",
                question: "關於鑑別式AI，下列敘述何者較為正確？",
                options: ["學習數據的聯合概率P(x,y)", "專注於數據的分類或迴歸任務", "主要用於生成新數據", "適合處理無標記數據"],
                correct: 1,
                explanation: "鑑別式AI學習的是條件概率P(y∣x)，用於分類或迴歸，並不適合生成數據或非監督式學習場景。"
            },
            {
                category: "科目一",
                question: "在醫學影像中，生成式AI和鑑別式AI的整合應用主要目的是什麼？",
                options: ["減少標記數據需求", "自動生成診斷結論", "提高診斷準確性和數據多樣性", "完全取代醫生的判斷"],
                correct: 2,
                explanation: "生成式AI用於生成多樣化數據，鑑別式AI提升診斷準確性，兩者結合可提高醫學影像分析的整體效能。"
            },
            {
                category: "科目一",
                question: "下列哪項是生成式AI支援鑑別式AI的典型案例？",
                options: ["模擬交通場景以訓練自動駕駛模型", "使用CNN對腫瘤分類", "使用SVM分析風險", "創建更好的分類演算法"],
                correct: 0,
                explanation: "生成式AI通常生成模擬場景數據，支援鑑別式AI進行模型訓練和決策。"
            },
            {
                category: "科目一",
                question: "下列哪種方法能解決生成式模型的訓練不穩定性問題？",
                options: ["使用更大的數據集", "採用Waserstein GAN(WGAN)", "提高硬體效能", "增加模型層數"],
                correct: 1,
                explanation: "Wasserstein GAN 透過改進損失函數提高了GAN模型的訓練穩定性，避免模式崩潰。"
            },
            {
                category: "科目一",
                question: "在整合應用中，生成式AI提供的數據增強主要解決了哪個問題？",
                options: ["模型過擬合", "數據稀缺或不平衡", "訓練過程的時間延遲", "數據隱私問題"],
                correct: 1,
                explanation: "生成式AI透過生成多樣化的數據樣本解決數據稀缺或不平衡問題，增強模型的泛化能力。。"
            },
            {
                category: "科目一",
                question: "未來整合鑑別式AI和生成式AI的關鍵方向是什麼？",
                options: ["增加生成模型的參數數量", "開發更高效的整合框架", "減少對標記數據的依賴", "將兩者獨立使用"],
                correct: 1,
                explanation: "整合框架的開發是未來的關鍵方向，旨在提升生成與分類模型的協同能力，實現更高效的應用。 "
            },
            {
                category: "科目一",
                question: "在使用 NotebookLM 生成簡報並搭配 DeckEdit 進行優化時，下列關於這套工作流程的敘述何者「完全正確」？",
                options: ["使用 DeckEdit 修改 NotebookLM 產出的簡報，主要能解決「重新生成」可能導致的字型崩壞或排版走樣問題。", "DeckEdit 透過 AI OCR 技術，讓原本不可編輯的 JPG/PDF 簡報檔變得能隨意挪動圖表位置並調整文字。", "DeckEdit 是一款付費訂閱制工具，但其強大之處在於能完美同步 NotebookLM 的動態排版更新。", "若在 DeckEdit 編輯模式中發現畫面像素較低且操作有延遲，應立即停止使用，以免導出的最終檔案模糊。"],
                correct: 0,
                explanation: "這是該工具的核心價值，透過直接在生成結果上修改文字，避免了因 AI 重新生成而產生的排版不可控風險。"
            },
            {
                category: "科目一",
                question: "Google Opal 的主要功能是什麼？",
                options: ["面向人工智慧開發者的複雜程式設計環境。", "一款由人工智慧驅動的影片編輯軟體。", "無需編碼即可實現自動化的「人工智慧樂高」。", "谷歌推出的全新社群媒體平台。"],
                correct: 2,
                explanation: ""
            },
            {
                category: "科目二",
                question: "關於No Code與Low Code的基本概念，以下哪一項最為正確？",
                options: [
                "No Code平台完全不需要任何技術知識，Low Code平台僅適合專業開發者使用",
                "No Code平台主要依靠圖形化介面(UI)進行開發，而Low Code平台結合了簡單程式設計與視覺化工具",
                "No Code 與 Low Code平台主要針對傳統IT團隊而設計",
                "Low Code平台完全不需要程式設計知識"
                ],
                correct: 1,
                explanation: "No Code平台的核心特點是使用圖形化介面(UI)讓用戶無需撰寫任何程式碼即可完成開發，而Low Code平台則是結合了少量程式設計與圖形化工具，適合具備基本技術能力的用戶。正確答案描述了兩者的特性，其他選項錯誤在於過於片面或不符合事實。"
            },
            {
                category: "科目二",
                question: "No Code / Low Code 技術的主要優勢不包括以下哪一項？",
                options: [
                "加速開發流程，降低企業開發成本",
                "幫助非技術人員創建應用和自動化流程",
                "完全消除對專業技術人員的需求",
                "加速企業數位轉型並提升競爭力"
                ],
                correct: 2,
                explanation: "No Code和Low Code平台可以大幅降低對專業技術人員的依賴，但不能完全取代他們，尤其是在需要高度客製化或複雜邏輯的應用場景中。。"
            },
            {
                category: "科目二",
                question: "下列何者最能表達No Code / Low Code平台的主要特色？",
                options: [
                "需要撰寫大量程式碼",
                "運用模板快速建立應用程式",
                "僅供專業開發人員使用",
                "只能製作靜態網站"
                ],
                correct: 1,
                explanation: "No Code / Low Code 平台的主要特色是提供視覺化界面與模板，讓使用者不需撰寫或僅需撰寫少量程式碼即可快速建立應用程式。這類平台適合非技術人員使用，支持動態與互動式應用的開發，降低開發門檻和時間成本。其他選項與此平台的核心特點不符。"
            },
            {
                category: "科目二",
                question: "關於No Code平台，下列敘述何者較為準確？",
                options: [
                "已經完全取代傳統的AI開發模式",
                "只適用於大型企業",
                "是一種降低AI技術複雜性和開發成本的新興方法",
                "工具都具有完全相同的功能和效能"
                ],
                correct: 2,
                explanation: "No Code平台是一種新興技術，透過圖形化介面及預建模組，使用者無需撰寫程式碼即可實現開發工作，從而有效降低技術複雜性與開發成本。"
            },
            {
                category: "科目二",
                question: "關於 No Code / Low Code 平台，下列敘述何者較正確？",
                options: [
                "兩者完全相同",
                "Low Code 平台不需要任何程式設計知識",
                "Low Code 平台更適合開發靈活且可擴展的解決方案",
                "No Code 平台可以無限客製化"
                ],
                correct: 2,
                explanation: "No Code 和 Low Code 平台雖然相似，但有明顯差異。No Code 平台完全針對非技術使用者設計，無需撰寫程式碼即可完成應用開發；而 Low Code 平台則適合具有基本程式知識的開發者，允許透過少量程式碼進行進一步的客製化，並具備更大的靈活性與擴展性，因此適合開發更複雜的解決方案。"
            },
            {
                category: "科目二",
                question: "下列哪一項不是 No Code / Low Code 平台在推動AI民主化過程中的挑戰？",
                options: ["使用者缺乏對 AI 的深層理解", "可能引發模型偏差 or 誤用", "需要加強人員相關教育和規範", "提供昂貴的開發工具"],
                correct: 3,
                explanation: "No Code 和 Low Code 平台在推動AI民主化過程中的挑戰包括使用者缺乏對AI的深層理解、可能引發模型偏差或誤用，以及需要加強人員相關教育和規範，而不是提供昂貴的開發工具。"
            },
            {
                category: "科目二",
                question: "生成式 AI 在金融業的應用不包括以下哪一項？",
                options: ["風險評估與管理", "投資組合優化", "自動化生成病歷", "提供個人化投資建議"],
                correct: 2,
                explanation: "生成式AI在金融業的應用包括風險評估與管理、投資組合優化和提供個人化投資建議，但自動化生成病歷是醫療領域的應用。"
            },
            {
                category: "科目二",
                question: "No Code 平台的設計目標是降低技術門檻，使哪一類使用者能夠開發應用程式，而無需撰寫程式碼？",
                options: ["技術專家", "非技術背景的使用者", "資深開發者", "系統管理員"],
                correct: 1,
                explanation: "No Code平台主要讓沒有程式設計背景的人也能輕鬆構建應用程式。這些平台提供直觀的圖形化界面和拖放工具，使使用者能夠透過簡單的操作來設計和開發應用程式，無需編寫程式碼。這相比之下，技術專家、資深開發者和系統管理員通常具備較高的程式設計能力，可能更傾向於使用Low Code平台或傳統的開發工具來實現更複雜和自訂的功能。因此，No Code平台的主要目標群體是非技術背景使用者，幫助他們提高生產力並減少對技術專家的依賴。"
            },
            {
                category: "科目二",
                question: "關於生成式AI與No Code / Low Code平台的應用，下列何者最不適合？",
                options: ["自動生成程式碼", "自動化生成行銷文案", "快速開發個人化App", "自動化生成法律判決"],
                correct: 3,
                explanation: "生成式AI可以根據使用者的需求自動生成程式碼，幫助完成複雜的客製化功能，節省開發時間；在行銷方面，輸入產品資訊後，AI能生成吸引人的行銷文案；基於使用者數據，AI還能快速開發符合個人需求的App。然而，自動化生成法律文件並不屬於這些平台的常見應用案例，因為法律判決的生成通常需要專業的法律知識和嚴格的合規性審查，這超出了 No Code / Low Code平台的主要功能範疇。法律文件的準確性和合法性至關重要，通常需要專業律師的參與和審核，而不是僅依賴自動化工具。"
            },
            {
                category: "科目二",
                question: "在選擇No Code / Low Code平台時，下列何者為考慮功能與擴展性時最重要因素？",
                options: ["平台的購買成本", "平台的技術整合能力和自訂性", "使用者的程式設計能力", "平台的市場評價"],
                correct: 1,
                explanation: "在選擇No Code / Low Code平台時，功能與擴展性是關鍵考量因素之一，包括平台的技術整合能力和自訂性。技術整合能力指的是平台能否與現有系統(如CRM、ERP等)無縫連接，確保資料流通和業務流程的順暢。自訂性則是指平台是否能夠滿足特定業務需求，提供足夠的自訂選項來適應不同的應用場景。這些因素直接影響平台的實用性和靈活性，使企業能夠根據自身需求進行調整和擴展。相比之下，平台的購買成本、使用者的程式設計能力和市場評價雖然也重要，但它們並不屬於功能與擴展性的範疇。"
            },
            {
                category: "科目二",
                question: "下列何者是使用生成式AI進行圖像生成時需要考慮的問題？",
                options: ["生成圖像的解析度", "版權和合法性", "模型的推論時間", "以上皆是"],
                correct: 3,
                explanation: "使用生成式AI進行圖像生成時，需考慮多方面問題：解析度：確保生成圖像符合應用需求，如高解析度對於專業設計和印刷尤為重要。版權與合法性：避免生成內容侵害他人版權或觸犯法律，尤其是在商業應用中。推論時間：確保模型生成圖像的效率能滿足實際應用需求，例如即時生成場景的要求。因此，這些因素都是需要考慮的重要問題。"
            },
            {
                category: "科目二",
                question: "學校教師如何引導學生正確使用生成式AI工具？",
                options: ["不應使用AI工具於教學場域", "無限制地使用AI工具", "訂立清晰的使用規範並進行說明", "僅鼓勵學生利用AI完成課堂作業"],
                correct: 2,
                explanation: "教師應引導學生正確使用生成式AI工具，避免過度依賴或誤用。制定清晰的使用規範，並向學生說明AI的適用場景、倫理考量及可能的限制，能幫助學生發展批判性思維。同時，規範使用能促進學生將AI工具作為輔助學習的資源，而非替代自主學習的過程。"
            },
            {
                category: "科目二",
                question: "下列哪一種技術方案適用於改善客戶體驗？",
                options: ["預測性維護工具", "自然語言處理(NLP)和生成式回應模組", "智慧排程系統", "消費行為洞察模型"],
                correct: 1,
                explanation: "NLP和生成式回應模組可以提升客服平台的效率和溝通品質。"
            },
            {
                category: "科目二",
                question: "下列哪一種方式可以有效幫助現職員工提升AI應用能力？",
                options: ["提高薪資來吸引AI人才", "安排跨部門交流和測試專案", "減少員工的工作負擔", "員工視需求選擇性自學AI技術"],
                correct: 1,
                explanation: "實務操作和交流有助於員工快速掌握AI技術，比單純自學效果更好。"
            },
            {
                category: "科目二",
                question: "下列何者為企業導入AI技術後最直接的影響？",
                options: ["增加人力需求", "提升生產力和效率", "減少數據處理能力", "降低市場競爭力"],
                correct: 1,
                explanation: "AI技術能有效提升生產力與效率，特別是在自動化流程與數據分析中。"
            },
            {
                category: "科目二",
                question: "下列哪一項技術是生成式AI的基礎？",
                options: ["決策樹模型", "生成對抗網路", "聚類演算法", "隨機森林技術"],
                correct: 1,
                explanation: "生成對抗網路是生成式人工智慧的核心技術之一，用於生成逼真的圖像和數據。"
            },
            {
                category: "科目二",
                question: "下列何者是人工智慧未來發展中最迫切需要解決的挑戰？",
                options: ["計算資源的過剩", "資料隱私與道德規範問題", "人才培育與跨領域合作的不足", "無法應用於小型企業場景"],
                correct: 1,
                explanation: "資料隱私保護和倫理規範的建立是AI技術進一步發展的關鍵挑戰。"
            },
            {
                category: "科目二",
                question: "使用生成式AI生成的內容時，應採取什麼措施以確保內容品質？",
                options: ["使用內容直接進行學術報告", "適當標注引用來源", "減少人工參與的審查過程", "排除所有生成的資料"],
                correct: 1,
                explanation: "在使用生成式AI生成的內容時，適當標注引用來源是確保內容品質的重要措施。這樣做可以避免抄襲，尊重原作者的知識產權，並提供內容的可靠性和可追溯性。直接使用生成的內容進行學術報告可能會導致學術不端行為，而減少人工參與的審查過程則可能降低內容的準確性和品質。完全排除所有生成的資料則過於極端，無法充分利用AI技術的優勢。因此，適當標注引用來源是最佳選擇"
            },
            {
                category: "科目二",
                question: "下列哪一項不是生成式AI工具在使用體驗方面的優化方向？",
                options: ["提供更直觀的操作設計", "支援自然語言指令", "提供智慧化的參數調整建議", "限制使用者自訂生成內容"],
                correct: 3,
                explanation: "生成式AI工具在使用體驗方面的優化方向包括提供更直觀的操作設計、支援自然語言指令以及提供智慧化的參數調整建議，而不是限制使用者自訂生成內容。"
            },
            {
                category: "科目二",
                question: "企業導入生成式AI的第一步應是什麼？",
                options: ["確保硬體設備升級", "設定可量化、可追蹤的經營目標", "安排員工進行AI相關培訓", "購買生成式AI相關軟體"],
                correct: 1,
                explanation: "設定明確目標是規劃AI導入的基礎，其他步驟都需要以此為依據。"
            },
            {
                category: "科目二",
                question: "以下哪一項屬於企業在評估導入生成式AI時需識別的問題領域？",
                options: ["市場趨勢預測能力有限", "設計更高效能的運算資源", "增加銷售團隊人力", "減少AI模型參數數量"],
                correct: 0,
                explanation: "評估問題領域需從企業現有瓶頸出發，市場趨勢預測能力不足是常見的挑戰。"
            },
            {
                category: "科目二",
                question: "企業若要有效支援生成式AI的運行，內部IT環境最需要具備下列何種條件？",
                options: ["提供更多的辦公設備，以提升員工生產力", "精簡企業內部流程，以加速決策效率", "擁有高效能運算資源與彈性儲存空間，以支援AI模型訓練與推理", "增加部門之間的交流機會，以促進跨部門合作"],
                correct:2,
                explanation: "此題聚焦於AI需要的核心IT基礎設施，生成式AI需要強大的運算資源和靈活的存儲環境來支持運行。"
            },
            {
                category: "科目二",
                question: "在生成式AI導入過程中，資料安全與隱私保護的哪一方面是最重要的考量？",
                options: ["權限控管與合規要求", "增強客服回饋(反饋)能力", "資料視覺化能力", "設定目標優先級"],
                correct: 0,
                explanation: "確保權限控管和合規是保障資料安全和避免法律風險的重要措施。"
            },
            {
                category: "科目二",
                question: "成功導入生成式AI的關鍵在於哪三個因素？",
                options: ["提供更多數據、加強合作、減少成本", "清晰定義痛點、技術匹配、培養人才", "投資高端設備、增加技術人員、縮短流程", "推行技術改革、調整市場策略、強化品牌"],
                correct: 1,
                explanation: "清晰目標、適配技術和人才培養是生成式AI成功應用的三大核心因素。"
            },
            {
                category: "科目二",
                question: "在導入生成式AI的構想階段，企業應首先專注於什麼？",
                options: ["提升內部資料儲存容量", "明確經營目標與核心價值", "進行員工AI基礎培訓", "購買市面上的AI軟體"],
                correct: 1,
                explanation: "企業應從經營目標、核心價值和長期策略出發，明確生成式AI的應用方向，這是成功導入的基礎。"
            },
            {
                category: "科目二",
                question: "在AI導入正式實施階段，企業應優先進行的活動是什麼？",
                options: ["增加行銷預算", "調整產品價格", "確保相關人員熟悉新流程與工具", "減少生產規模以減少風險"],
                correct: 2,
                explanation: "員工熟悉新流程和工具是AI成功應用的基礎，確保業務能順利過渡。"
            },
            {
                category: "科目二",
                question: "下列何者為風險分析階段的主要目的？",
                options: ["找到更多的數據來源", "增強模型的效能", "評估風險的影響與發生可能性", "降低模型運行成本"],
                correct: 2,
                explanation: "風險分析的重點是根據影響程度與發生機率，評估風險的嚴重性，從而進行分級與資源分配。"
            },
            {
                category: "科目二",
                question: "若企業將資料安全管理外包給第三方服務供應商，屬於哪種風險應對策略？",
                options: ["風險緩解", "風險轉移", "風險接受", "風險規避"],
                correct: 1,
                explanation: "透過外包或購買保險等方式，企業將潛在風險轉移至第三方來處理。"
            },
            {
                category: "科目二",
                question: "為了確保風險管理的持續有效性，企業應如何應對風險管理策略的效果下降？",
                options: ["繼續沿用原策略", "停止AI應用以防意外", "快速調整並進行必要改進", "將策略移交給外部顧問"],
                correct: 2,
                explanation: "當發現策略效果下降時，企業應主動調整策略並進行改進，確保風險管理的持續有效性。"
            },
            {
                category: "科目二",
                question: "在生成式AI的推理機制中，哪一個參數主要用來控制生成內容的隨機性，當數值較高時會產生更具創意的內容？",
                options: ["學習率 (Learning Rate)", "溫度參數 (Temperature Parameter)", "批次大小 (Batch Size)", "訓練週期 (Epochs)"],
                correct: 1,
                explanation: "溫度參數用於控制生成內容的隨機性，低溫度值生成保守內容，高溫度值則生成更具創意的內容。"
            },
            {
                category: "科目二",
                question: "企業在評估導入 No Code 或 Low Code 平台時，若該應用場景需要「高度自訂性」與「複雜邏輯」，下列哪種平台較為適合？",
                options: ["No Code 平台", "Low Code 平台", "RPA 流程自動化", "傳統手寫程式"],
                correct: 1,
                explanation: "Low Code 平台結合視覺化工具與少量程式碼，適合需要高彈性、複雜邏輯及高度自訂性的應用開發。"
            },
            {
                category: "科目二",
                question: "在生成式AI的技術架構中，哪一種機制特別有助於處理序列數據中的長距離依賴關係？",
                options: ["標記化處理 (Tokenization)", "數據清洗 (Data Cleaning)", "注意力機制 (Attention Mechanism)", "向量化表示 (Vectorization)"],
                correct: 2,
                explanation: "注意力機制(尤其是自注意力)有助於處理長距離依賴關係，並有效學習序列數據的內在結構。"
            },
            {
                category: "科目二",
                question: "關於「AI 民主化 (AI Democratization)」的敘述，下列何者正確？",
                options: ["指AI技術僅限於大型科技公司使用", "旨在降低技術門檻，讓非技術背景人士也能參與開發", "指完全取代專業程式開發者的過程", "指AI模型不再需要數據訓練"],
                correct: 1,
                explanation: "AI民主化是指降低技術門檻，讓更多非技術背景的人士與中小型企業能參與AI開發並受益 。"
            },
            {
                category: "科目二",
                question: "在生成式AI導入的驗證(POC)階段，若要衡量「文本生成」模型的品質與流暢性，常用哪種量化指標？",
                options: ["ROI (投資報酬率)", "TCO (總擁有成本)", "BLEU / ROUGE", "KPI (關鍵績效指標)"],
                correct: 2,
                explanation: "評估生成式AI模型效能時，常用 BLEU、ROUGE、Perplexity 等量化標準來衡量內容品質與流暢性。"
            },
            {
                category: "科目二",
                question: "企業面對生成式AI風險時，若採取「暫緩開發高風險應用」的策略，這屬於哪一種風險應對方式？",
                options: ["風險緩解", "風險轉移", "風險接受", "風險迴避"],
                correct: 3,
                explanation: "風險迴避適用於技術不成熟或可能導致重大損害的場景，企業可暫緩開發或推進高風險應用。"
            },
            {
                category: "科目二",
                question: "在 No Code 平台中，非技術背景的員工利用工具自動化日常工作(如報告生成)，這類人員通常被稱為：",
                options: ["提示工程師 (Prompt Engineer)", "市民開發者 (Citizen Developer)", "資料科學家 (Data Scientist)", "系統架構師 (System Architect)"],
                correct: 1,
                explanation: "利用 No Code/Low Code 工具自動化工作、提高生產力的非技術背景人士被稱為「市民開發者」。"
            },
            {
                category: "科目二",
                question: "生成式AI在「製造業」的應用中，下列何者屬於優化生產流程的方式？",
                options: ["自動生成藥物分子結構", "模擬市場情境進行風險評估", "提供製程改善建議與自動化生產", "生成個人化行銷文案"],
                correct: 2,
                explanation: "製造業應用包括產品設計原型製作，以及透過數據分析提供製程改善建議，實現自動化與精準生產。"
            },
            {
                category: "科目二",
                question: "在導入規劃的「準備階段」，企業應優先執行哪一類 AI 應用項目？",
                options: ["技術難度極高且需長期研發的項目", "低技術難度且能快速產生效益的試點場景", "不具商業價值但具備創意的項目", "需消耗所有運算資源的單一模型"],
                correct: 1,
                explanation: "在初始階段企業應集中資源於小範圍試點，優先執行低技術難度且能快速產生效益的場景。"
            },
            {
                category: "科目二",
                question: "哪一種推理採樣方法是透過選擇「累積機率」達到某一閾值(如0.9)的選項來平衡內容品質與隨機性？",
                options: ["頂部採樣 (Top-k Sampling)", "核採樣 (Nucleus Sampling)", "貪婪搜尋 (Greedy Search)", "隨機採樣 (Random Sampling)"],
                correct: 1,
                explanation: "核採樣(Nucleus Sampling)是選擇累積機率達到某一閾值的選項進行採樣。"
            },
            {
                category: "",
                question: "下列哪一項最符合 No Code / Low Code 平台的主要特色",
                options: ["需要撰寫大量底層程式碼以確保效能","運用模板（Templates）與視覺化組件快速建立應用程式","僅能用於製作簡單的靜態網頁","核心目標是完全取代所有專業軟體工程師"],
                correct: 1,
                explanation: "這些平台透過視覺化介面、模板與即用型模組，降低開發門檻並縮短上市時間"
            },
            {
                category: "科目二",
                question: "企業在進行「概念驗證（Proof of Concept, POC）」階段時，主要目的為何？",
                options: ["將 AI 系統推廣至全公司所有部門使用","透過小規模實驗，驗證技術在真實業務場景中的可行性與成效","採購最高規格的硬體伺服器","取代所有現有的人工作業流程"],
                correct: 1,
                explanation: "POC 是用來評估模型效能與業務融合度，確認具有商業價值後才考慮擴大導入。"
            },
            {
                category: "科目一",
                question: "下列哪一種特徵工程技巧，最適合將「星期幾」和「24小時制時間」這兩個欄位結合，以預測通勤時間？",
                options: ["特徵交叉（Feature Cross） ","寬深模型（Wide and Deep）","正規化（Normalization）","One-hot編碼（One-hot encoding）"],
                correct: 0,
                explanation: "特徵交叉（Feature Cross）是將兩個或多個特徵結合產生新特徵的方法，適合用於將「星期幾」和「時間」結合以預測通勤時間。"
            },
            {
                category: "科目一",
                question: "關於資料正則化（Regularization）L1、L2方法，下列敘述何者正確？",
                options: ["L1運用減少權重的絕對值來控制模型的複雜度","L2較L1正則化方法會將特徵權重趨近於零","L2稱為Lasso正則化","L1權重個數愈多，愈可以提升模型的正確率"],
                correct: 0,
                explanation: "L1正則化透過減少權重的絕對值來控制模型複雜度，L2則透過減少權重平方和來達成類似效果。L2正則化稱為Ridge正則化，而非Lasso。"
            },
            {
                category: "科目一",
                question: "在機器學習中，「偏差與變異權衡（Bias-Variance Tradeoff）」主要用來解決下列哪一類型的問題？",
                options: ["如何在模型偏差與變異之間取得平衡，以避免過度擬合或欠擬合","訓練資料中類別分布不均，使模型在少數類別上表現不佳","測試資料樣本與訓練資料高度重複，造成模型泛化能力評估失準","因資料來源或收集方式限制，導致模型學習到的資訊不足"],
                correct: 0,
                explanation: "偏差與變異權衡是機器學習中用來平衡模型過度擬合（高變異）與欠擬合（高偏差）的問題。"
            },
            {
                category: "科目一",
                question: "在Lasso模型中，L1正則化（Regularization）導致參數收斂為零的原因為何？",
                options: ["L1對大係數懲罰較強，促使稀疏解","L1會轉換損失函數為非凸形 ","L1對梯度有平滑作用","L1正則化忽略目標變數"],
                correct: 0,
                explanation: "L1正則化會對大係數施加較強的懲罰，促使模型產生稀疏解，即部分參數收斂為零。"
            },
            {
                category: "科目一",
                question: "貝氏分類器（Naive Bayes Classifier）常被應用於文字分類、垃圾郵件過濾等場景。依據模型特性，它最適合歸類於下列哪一類？",
                options: ["透過建構資料的整體分布，並利用條件關係進行推斷和分類的模型","透過試錯學習，根據行動結果的獎勵或懲罰來優化決策策略的模型","側重探索資料中樣本間的相似性，將資料自動分成不同群組的模型","透過直接學習輸入特徵與目標標籤之間的邊界或關係來進行分類的模型"],
                correct: 0,
                explanation: "貝氏分類器是基於機率理論，透過建構資料的整體分布並利用條件關係進行推斷和分類的模型。"
            },
            {
                category: "科目一",
                question: "為提升生成式AI系統回應的語境一致性，常會結合哪類模型技術？",
                options: ["條件語言模型（Conditional Language Model）","決策樹分類器（Decision Tree Classifier）","強化學習Q-learning函數模型","基因演算法（Genetic Algorithm）"],
                correct: 0,
                explanation: "條件語言模型（Conditional Language Model）能根據上下文語境生成更一致的回應。"
            },
            {
                category: "",
                question: "根據2025年9月行政院通過之《人工智慧基本法》草案，政府推動人工智慧之「創新實驗環境」制度，主要參考歐盟的何種制度？",
                options: ["Regulatory Sandbox","AI Ethics Review Board ","AI Trust Label","Data Protection Impact Assessment"],
                correct: 0,
                explanation: "Regulatory Sandbox 是歐盟推動人工智慧創新實驗環境的主要制度。"
            },
            {
                category: "科目一",
                question: "根據《金融機構運用人工智慧技術作業規範》，金融機構須建立內部治理架構，並指定專責單位或人員負責推動及管理人工智慧事務，下列何者並非規範所明訂須落實的治理措施？",
                options: ["每日公布人工智慧系統運作狀況","指派高階主管或委員會進行監督管理","清楚了解生成式 AI 技術之運作模式","辦理人工智慧人才培育"],
                correct: 0,
                explanation: "每日公布人工智慧系統運作狀況並非規範所明訂須落實的治理措施。"
            },
            {
                category: "科目一",
                question: "下列哪一類問題最適合使用非監督式學習（Unsupervised Learning）來處理？",
                options: ["根據使用者行為將用戶分群，以優化行銷策略","根據歷史股價預測未來股市的走勢","透過已知交通事故記錄預測未來事故發生機率","根據已標記的醫療影像訓練模型診斷疾病"],
                correct: 0,
                explanation: "非監督式學習適用於無標記資料的問題，如用戶分群。"
            },
            {
                category: "科目一",
                question: "下列哪一種圖表最適合用來呈現並分析「兩個數值型變數」之間的關係，例如觀察身高與體重的相關性？",
                options: ["散佈圖（Scatter Plot）","折線圖（Line Chart）","直方圖（Histogram）","長條圖（Bar Chart）"],
                correct: 0,
                explanation: "散佈圖最適合用來呈現兩個數值型變數之間的關係，例如觀察身高與體重的相關性。"
            },
            {
                category: "科目一",
                question: "下列哪一項應用情境與機器學習類型搭配正確？",
                options: [
                    "在醫療影像資料中，僅有少部分影像有專家標註診斷，其餘大多數影像未標註，研究者結合已標註與未標註資料來建立模型 — 監督式學習 (Supervised Learning)",
                    "在自駕車模擬環境中，模型透過試駕獲得「是否安全通過路口」的獎勵或懲罰訊號，逐步調整決策策略 — 非監督式學習 (Unsupervised Learning)",
                    "在顧客購買紀錄中，利用已知的「顧客是否流失」標籤，訓練模型以預測新顧客未來是否會流失 — 強化式學習 (Reinforcement Learning)",
                    "在股票市場資料中，輸入歷史股價序列，嘗試將未來可能走勢劃分成若干「上升型、盤整型、下降型」群組，無需使用任何標籤 — 非監督式學習 (Unsupervised Learning)"
                ],
                correct: 3,
                explanation: "群聚分析 (Clustering)是在無標籤情況下將資料分群，屬於典型的非監督式學習。其餘選項錯誤原因：醫療影像為半監督式學習；自駕車為強化式學習；顧客購買紀錄為監督式學習。"
            },
            {
                category: "科目一",
                question: "某企業分析團隊正在處理一組近兩年的營運與銷售數據，共有四個部門提出了各自的分析需求，請判斷哪一個最接近「預測性分析 (Predictive Analysis)」的特性？",
                options: [
                    "視覺化所有產品線過去月銷售走勢與標準差，觀察其分佈情況與波動程度",
                    "藉由資料比對分析，找出去年母親節促銷失效的地區與品類組合",
                    "建構模型推算下一季的主力商品銷量，以規劃備貨與倉儲資源配置",
                    "透過熱圖分析廣告投放成本與訂單轉換率之間的潛在關聯性"
                ],
                correct: 2,
                explanation: "預測性分析的核心在於「利用歷史數據推估未來」。(C) 選項提到『推算下一季銷量』，屬於對未來事件的預測。其他選項：(A) 為敘述性分析 (Descriptive)；(B) 為診斷性分析 (Diagnostic)；(D) 為診斷性分析（探索關聯）。"
            },
            {
                category: "科目一",
                question: "某模型使用 K-近鄰演算法（KNN）進行分類，K 設為 3。一筆新的測試資料輸入後，與其最接近的 3 筆資料的類別如下：鄰近樣本 1：類別 A；鄰近樣本 2：類別 B；鄰近樣本 3：類別 A。請問模型會將這筆資料預測為哪一類別？",
                options: [
                    "類別 A",
                    "類別 B",
                    "類別 A 與 B 各一半，無法分類",
                    "類別 A 或 B，視距離遠近加權而定"
                ],
                correct: 0,
                explanation: "KNN 演算法的分類原理是「多數決」。當 K=3 時，鄰近的 3 個樣本中有 2 個屬於類別 A，1 個屬於類別 B，因此模型會將新資料預測為類別 A。"
            },
            {
                category: "科目一",
                question: "某團隊想採用循環神經網路（Recurrent Neural Network, RNN）建構長期氣候數據的預測模型，以下哪一項敘述最符合使用 RNN 可能會遇到的挑戰？",
                options: [
                    "RNN 無法處理可變長度的序列輸入，因此在實務上限制極大",
                    "RNN 在長序列訓練中可能出現梯度消失，影響模型效果",
                    "RNN 無法捕捉時間上的依賴關係，因此預測準確度低",
                    "RNN 只能用於分類任務，不能應用於時間序列預測"
                ],
                correct: 1,
                explanation: "RNN 最大的技術痛點在於處理「長序列」時容易遇到梯度消失（Vanishing Gradient）或梯度爆炸問題，這也是後來發展出 LSTM 或 GRU 的主因。"
            },
            {
                category: "科目一",
                question: "一間金融科技公司設計一款智慧投資系統，該系統會根據市場變化自動決定「買進」、「持有」或「賣出」的行動，並根據每次交易後的盈虧結果，逐步優化下一次的投資策略。整個過程中，系統不依賴事先標記的資料，而是根據歷次行動獲得的獎勵進行調整。請問此系統最可能採用哪一種學習方法？",
                options: [
                    "強化式學習 (Reinforcement Learning)",
                    "監督式學習 (Supervised Learning)",
                    "非監督式學習 (Unsupervised Learning)",
                    "遷移學習 (Transfer Learning)"
                ],
                correct: 0,
                explanation: "強化式學習的特徵是透過與環境互動、獲得「獎勵」或「懲罰」來優化決策策略。題目提到的「根據盈虧結果（獎勵）優化投資行動」完全符合此定義。"
            },
            {
                category: "科目一",
                question: "關於 Q-Learning 與 Deep Q-Learning，下列敘述何者最正確？",
                options: [
                    "Q-Learning 與 Deep Q-Learning 的差異在於是否使用標記資料作為學習基礎",
                    "Q-Learning 可處理任意維度的狀態空間，因此比 Deep Q-Learning 更靈活",
                    "Deep Q-Learning 透過深度神經網路近似 Q 值，避免了 Q 表在高維空間中難以擴展的問題",
                    "Deep Q-Learning 無法搭配經驗回放（Experience Replay），因為會導致樣本順序被打亂"
                ],
                correct: 2,
                explanation: "傳統 Q-Learning 使用表格（Q-table）儲存狀態與行為的價值，當狀態過多時會產生「維度災難」。Deep Q-Learning（DQN）改用神經網路來預估這些價值，能有效處理複雜的高維問題。"
            },
            {
                category: "科目一",
                question: "在訓練機器學習模型時，若任務為預測房價，應選用下列哪一種損失函數（Loss Function）來衡量預測誤差？",
                options: [
                    "均方誤差 (MSE)",
                    "交叉熵損失 (Cross-Entropy Loss)",
                    "Hinge 損失 (Hinge Loss)",
                    "KL 散度 (Kullback-Leibler Divergence)"
                ],
                correct: 0,
                explanation: "預測房價屬於「迴歸問題」，目標是預測一個連續的數值，因此通常使用均方誤差 (MSE) 或平均絕對誤差 (MAE) 來衡量預測值與真實值之間的差距。交叉熵與 Hinge 損失則常用於分類問題。"
            },
            {
                category: "科目一",
                question: "某醫院希望開發一個系統，根據患者的年齡、血壓與BMI等資訊，預測其罹患糖尿病的機率（0~1），並依據預測值是否超過0.5做出風險警示。下列哪一種模型最適合用於此分類任務？",
                options: ["邏輯迴歸（Logistic Regression）","支援向量機（Support Vector Machine）；","決策樹（Decision Tree）","K平均演算法（K-means） "],
                correct: 0,
                explanation: "邏輯迴歸是處理二元分類問題的經典方法，特別適合用於預測機率並設定閾值（如0.5）進行分類。"
            },
            {
                category: "科目一",
                question: "某金融科技公司正開發一套違約風險預測系統，需大量處理不同客戶的財務特徵資料。考量到資料特徵數量眾多，且希望提升預測的穩定性與泛化能力，下列哪一種鑑別式 AI 模型最適合？",
                options: [
                    "邏輯迴歸 (Logistic Regression)",
                    "支援向量機 (Support Vector Machine)",
                    "決策樹 (Decision Tree)",
                    "隨機森林 (Random Forest)"
                ],
                correct: 3,
                explanation: "隨機森林（Random Forest）是一種集成學習方法，透過組合多棵決策樹來提升預測的穩定性並防止過擬合。面對大量特徵時，它具有良好的泛化能力與抗噪性。"
            },
            {
                category: "科目一",
                question: "關於變分自編碼器 (Variational Autoencoder, VAE) 的運作流程，下列何者敘述最為正確？",
                options: [
                    "解碼器的任務是將低維壓縮向量分類為不同類別",
                    "編碼器將輸入資料轉換為可視化圖像以利模型學習",
                    "編碼器將資料轉換為潛在空間表示，解碼器再重建資料",
                    "編碼器利用最大邊際機率對資料進行異常點偵測"
                ],
                correct: 2,
                explanation: "VAE 的核心運作機制是透過編碼器（Encoder）將輸入資料映射到潛在空間（Latent Space）的分佈表示，再由解碼器（Decoder）從該空間中取樣並嘗試重建原始資料。"
            },
            {
                category: "科目一",
                question: "下列何者不是我國數位發展部 AI 產品與系統評測中心對生成式 AI 的評測項目？",
                options: [
                    "當責性",
                    "可靠性",
                    "隱私及資安",
                    "互動性"
                ],
                correct: 3,
                explanation: "數位發展部 AI 評測中心主要針對安全性、穩定性與倫理進行規範，評測項目包含當責性、可靠性、隱私及資安、公平性等。而「互動性」屬於使用者體驗範疇，並非安全評測的覈心項目。"
            },
            {
                category: "科目一",
                question: "在保持 GPT-OSS 模型架構不變的前提下，如果將模型參數量從 20 億提升至 120 億，並假設有足夠的訓練資料支撐，下列敘述何者最正確？",
                options: [
                    "模型參數增加會線性提升效能，且即使訓練資料不變也不會遇到瓶頸",
                    "參數越多模型推理越快，因為每層可以並行計算更多參數",
                    "較大的參數量能提升模型的表達能力與預測效能，但需足夠訓練資料支持",
                    "增加參數量不影響記憶體使用，只會影響計算速度"
                ],
                correct: 2,
                explanation: "模型參數增加通常能提升捕捉複雜模式的能力（表達能力），但為了避免過擬合（Overfitting），必須配合相對應規模的訓練資料（Scaling Laws）。增加參數也會導致推理速度變慢且記憶體需求增加。"
            },
            {
                category: "科目一",
                question: "在自然語言處理任務中，為了減少訓練語料中偏見對模型的影響，下列哪種資料處理策略屬於常見的「資料去偏（Data Debiasing）」做法？",
                options: ["調整或擴充訓練語料，使不同群體或類型資料的比例更加平衡，避免模型過度偏向出現頻率高的類別","讓模型在訓練時隨機替換輸出，以抵消資料中存在的系統性偏差","增加模型的參數量，依賴更大的模型自動消除原始資料中的偏見","對訓練資料施加額外正則化或噪音，使模型在學習過程中對偏見敏感度降低"],
                correct: 0,
                explanation: "調整或擴充訓練語料，使不同群體或類型資料的比例更加平衡，是常見的資料去偏策略。這能有效減少模型對特定群體的偏見。"
            },
            {
                category: "科目一",
                question: "在深度學習模型的微調 (Fine-tuning) 過程中，可能出現所謂的「災難性遺忘 (Catastrophic Forgetting)」。此現象最可能造成哪種情況？",
                options: [
                    "由於計算資源或訓練步驟不足，模型在微調過程中無法完整收斂，導致學習效果受限",
                    "微調後模型的表現變得隨機，無法有效記憶新學到的模式與知識",
                    "微調後模型的部分權重產生偏移，導致模型無法針對較長的文字進行回應",
                    "模型過度適應微調的資料分佈，逐漸遺忘先前預訓練所獲得的廣泛知識，在原有任務或廣泛領域上表現變差"
                ],
                correct: 3,
                explanation: "災難性遺忘是指模型在學習新任務（微調）時，新權重過度覆蓋了舊權重，導致模型喪失了在預訓練階段習得的通用能力。"
            },
            {
                category: "科目一",
                question: "在大型 Transformer 模型的效能優化過程中，常見的方法之一是「剪枝 (Pruning)」。下列哪一項最符合該核心方法的核心概念？",
                options: [
                    "將模型中所有權重按比例縮小，使其值更接近於零，以降低計算量",
                    "移除模型中影響較小或冗餘的部分權重參數，以減少模型大小並提升推理效率",
                    "在訓練時僅更新部分權重而將其他權重凍結，從而減少需要調整的參數數量",
                    "根據注意力分數動態跳過處理部分輸入 Token，以減少每次前向傳播的計算"
                ],
                correct: 1,
                explanation: "剪枝的核心在於「去蕪存菁」，透過識別並刪除對模型輸出貢獻度低的權重（如接近 0 的權重），在儘量維持準確度的情況下精簡模型體積。"
            },
            {
                category: "科目一",
                question: "對非常長的輸入序列進行推理 (Inference)，Transformer 模型推理的主要計算瓶頸通常是什麼？",
                options: [
                    "模型輸出層產生文本的過程，因為每生成一個詞都必須重新訓練整個模型一次",
                    "詞嵌入 (Embedding) 查找操作，因為其時間複雜度隨詞彙表大小指數級增長",
                    "Softmax 函數的計算，因為對每個 Token 都需要執行繁重的運算",
                    "自注意力層的計算與其記憶體使用，因為注意力矩陣的大小隨序列長度呈平方級增長"
                ],
                correct: 3,
                explanation: "Transformer 的自注意力機制（Self-Attention）需要計算序列中兩兩 Token 間的相關性，其計算與空間複雜度皆為 $O(n^2)$，因此長序列會導致計算量與記憶體需求暴增。"
            },
            {
                category: "科目一",
                question: "在「可解釋人工智慧（Explainable AI, XAI）」領域中，LIME（Local Interpretable Model-agnostic Explanations）方法最核心的應用目的是什麼？",
                options: [
                    "解釋單一樣本（局部預測）的黑箱模型決策過程",
                    "全面提升黑箱模型整體的預測準確度",
                    "將黑箱模型轉換成完全可解釋的模型作為替代",
                    "用於生成大量擬真數據來替代訓練集"
                ],
                correct: 0,
                explanation: "LIME 的核心在於「局部可解釋性」。它透過在單一資料點附近擾動輸入並觀察輸出變化，建立一個簡單的可解釋模型（如線性模型）來近似黑箱模型在該點的決策行為。"
            },
            {
                category: "科目一",
                question: "在醫療診斷決策支援系統等高風險領域中，「可解釋人工智慧（Explainable AI, XAI）」的核心價值最主要呈現在哪個面向？",
                options: [
                    "透過提供可理解的決策依據，促進患者與醫療專業人員對系統診斷結果的信任與接受度",
                    "以可解釋性方法優化臨床資料蒐集與管理流程，從而降低整體醫療作業成本",
                    "利用解釋機制增強模型預測的統計顯著性與準確度，使其在研究及實務應用中更具科學性",
                    "透過提供透明化的運作過程，進而減輕臨床人員負擔，並提升醫療服務的整體效率"
                ],
                correct: 0,
                explanation: "在高風險領域（如醫療、金融），AI 的決策必須具備可追蹤性。XAI 提供的解釋能讓醫生理解 AI 為何給出特定診斷，這對於建立人機協作的「信任」至關重要。"
            },
            {
                category: "科目一",
                question: "在金融科技公司的信貸決策系統中，導入反事實解釋（Counterfactual Explanation）時，實際部署往往伴隨技術與監管挑戰。下列哪一項最符合該情境下的核心挑戰？",
                options: [
                    "需要建立完整的客戶行為預測模型來估算建議改變的實施成本，並整合到現有的風險管理系統架構中",
                    "必須使用聯邦學習技術保護客戶隱私，同時在分散式環境中計算跨機構的反事實解釋結果",
                    "需要建構時間序列因果圖來處理客戶信用狀況的動態變化，並預測未來可能的信用評分軌跡",
                    "生成的反事實樣本必須滿足特徵間的因果約束和業務邏輯約束，同時確保建議的改變在現實中具有可操作性且符合公平放貸法規"
                ],
                correct: 3,
                explanation: "反事實解釋的核心挑戰在於生成的「如果怎樣，就會怎樣」建議必須在現實中可行（例如：不能建議客戶改變性別或減少出生年份），且須符合法律規範，這比單純生成數學樣本困難許多。"
            },
            {
                category: "科目一",
                question: "在統計推論中，若樣本來自母體但呈現明顯偏態分布，且樣本數有限，下列哪一項策略最能減少推估母體參數的偏誤？",
                options: [
                    "直接使用樣本平均數與變異數估計母體參數，不做任何調整",
                    "增加樣本數並考慮使用分位數或中位數作為中心趨勢估計",
                    "將樣本隨機重新排列後，多次計算平均值以消除偏態影響",
                    "完全依賴樣本標準差來估計母體參數，忽略分布形態"
                ],
                correct: 1,
                explanation: "當資料呈現偏態（Skewed）且樣本數小時，平均數容易受極端值影響。使用中位數或分位數（Robust statistics）能提供更穩健的中心趨勢估計；同時增加樣本數也有助於更精確地掌握分布全貌。"
            },
            {
                category: "科目一",
                question: "在工業物聯網架構中，進行設備預測性維護（Predictive Maintenance）時，若面對異常事件發生頻率極低、樣本高度不平衡的時間序列資料，下列哪一種方法最能兼顧模型穩定性與異常偵測效能？",
                options: [
                    "將每筆異常事件資料複製多次以提升模型對異常的辨識敏感度，搭配全序列訓練模型（如 LSTM）",
                    "對時間序列進行差分與標準化後，使用傳統監督式學習模型（如 SVM）進行分類訓練",
                    "使用經過時間序列特化的 SMOTE 技術生成異常樣本，以平衡異常與正常資料比例",
                    "採用基於重建誤差的自編碼器模型（Sequence-to-Sequence Autoencoder）進行異常偵測，並僅使用正常資料進行訓練"
                ],
                correct: 3,
                explanation: "在極度不平衡且異常樣本極少的情況下，監督式學習（如複製樣本或 SMOTE）容易過擬合。使用自編碼器（Autoencoder）進行「半監督式學習」，讓模型只學習正常資料的特徵，當輸入異常資料時，重建誤差（Reconstruction Error）會明顯偏高，是實務上偵測罕見異常最穩健的方法。"
            },
            {
                category: "科目一",
                question: "在零售業進行客戶行為分析時，資料倉儲中發現多個欄位儲存相同的購買金額資訊（例如：amount_usd、total_price、transaction_value），但其單位、命名慣例及格式不一致，進而導致特徵工程階段混淆模型輸入。針對此種跨欄位語義重疊與結構冗餘問題，下列哪一種資料處理策略最合適且具實務可行性？",
                options: [
                    "利用資料探勘技術自動選擇資料集中對目標變數最敏感的欄位，其他欄位捨棄即可，避免過度清理干擾原始結構",
                    "保留所有相似欄位，交由高階模型（如 Gradient Boosting 或 Deep Learning）自動學習特徵關聯，無需手動處理",
                    "建立欄位命名標準，統一金額單位與格式，進行欄位正規化與語義合併，減少重複資訊影響特徵重要性估計",
                    "將重複欄位視為類別欄位，進行 One-hot 編碼（One-hot encoding）後輸入模型，以避免數值誤導模型學習過程"
                ],
                correct: 2,
                explanation: "面對資料冗餘（Redundancy）與語義重疊，最正本清源的做法是進行「資料清洗」與「資料整合」。透過統一命名標準與格式（Normalization），並將相同語義的欄位合併，能有效降低模型的特徵維度，並避免模型因高度共線性（Multicollinearity）而產生錯誤的特徵重要性判斷。"
            },
            {
                category: "科目一",
                question: "某電信公司在進行客戶流失預測時，發現資料集包含大量類別型變數（如：居住地區、方案類型），且部分欄位的基數 (Cardinality) 極高（例如：超過 100 個不同的地區名稱）。下列哪一種特徵編碼方式在此情境下最不合適？",
                options: [
                    "獨熱編碼 (One-hot Encoding)",
                    "目標編碼 (Target Encoding)",
                    "標籤編碼 (Label Encoding)",
                    "計數編碼 (Count Encoding)"
                ],
                correct: 0,
                explanation: "當類別基數極高時，獨熱編碼會產生大量稀疏欄位，導致維度災難（Curse of Dimensionality），增加計算負擔並容易導致模型過擬合。"
            },
            {
                category: "科目一",
                question: "在機器學習模型的生命週期中，關於「特徵工程 (Feature Engineering)」與「模型訓練 (Model Training)」之間的關係，下列敘述何者最正確？",
                options: [
                    "特徵工程僅需在模型訓練前執行一次，模型部署後即不再更動特徵處理邏輯",
                    "只要模型演算法足夠強大（如深度學習），完全不進行特徵工程也能達到最優效能",
                    "高品質的特徵工程往往比選擇複雜的演算法更能有效提升模型的預測表現與泛化能力",
                    "特徵工程的主要目的是增加特徵數量，數量越多模型預測準確度必然越高"
                ],
                correct: 2,
                explanation: "資料品質與特徵表達能力是機器學習的基礎。良好的特徵工程能協助模型更容易捕捉資料規律，其對效能的提升往往大於單純更換更複雜的演算法。"
            },
            {
                category: "科目一",
                question: "在機器學習流程中，針對「特徵縮放（Feature Scaling）」的敘述，下列何者最正確？",
                options: [
                    "在使用決策樹（Decision Tree）或隨機森林（Random Forest）模型時，特徵縮放是提升模型準確度的必要步驟",
                    "標準化（Standardization）是將資料轉換為均值為 0、標準差為 1 的分布，對受異常值影響的資料具有較佳的穩定性",
                    "正規化（Normalization）是將資料縮放到指定的區間（如 0 到 1），這會導致原始資料的分布形態完全消失",
                    "特徵縮放僅是為了讓資料可視化更美觀，對基於梯度下降（Gradient Descent）的演算法效能沒有影響"
                ],
                correct: 1,
                explanation: "標準化（Standardization）將特徵轉換為標準常態分佈，相較於正規化（Min-Max Scaling），它對於異常值（Outliers）的魯棒性（Robustness）通常更好。此外，樹狀模型通常不需要特徵縮放，而基於梯度的演算法則非常依賴它。"
            },
            {
                category: "科目一",
                question: "某電商資料團隊要協助行銷部門規劃再行銷策略。目前取得資料包含使用者點擊、購買紀錄、流量來源與轉換率。若資料團隊希望先進行探索性資料分析（EDA），下列哪一項最符合 EDA 的做法？",
                options: [
                    "建立隨機森林模型，預測使用者是否會完成購買",
                    "使用 K-means 對使用者群進行分群並立即制定對應促銷策略",
                    "繪製各類流量來源對轉換率的關聯圖，尋找潛在關係",
                    "對不同購物路徑設定統計假設並進行雙樣本 t 檢定"
                ],
                correct: 2,
                explanation: "探索性資料分析（EDA）的主要目的是透過視覺化與統計工具來理解資料特徵與尋找變數間的關係，而非直接建立預測模型。繪製關聯圖是典型的 EDA 做法。"
            },
            {
                category: "科目一",
                question: "某金融科技公司在利用歷史交易資料建立風險控管模型時，嘗試推估整體詐騙交易比例。近期發現，樣本間存在明顯的時間序列相關性，導致模型在實際偵測新交易時誤判率升高。若希望同時改善詐騙比例推估的準確性並提升模型的穩健性，下列哪一種做法最為合適？",
                options: [
                    "擴充樣本數量，以涵蓋更多潛在的詐騙型態，但維持既有的隨機抽樣方式不變",
                    "採取時間序列敏感的抽樣策略，例如依據交易時間區間進行分層，以保存原始的時間結構特性",
                    "將資料完全隨機打散，以降低序列相關性對模型訓練造成的影響",
                    "在模型評估時，針對相鄰時間區段進行誤差合併，以便用整體估計方式修正詐騙比例"
                ],
                correct: 1,
                explanation: "當資料具備時間序列特性時，隨機抽樣會破壞時間結構。採取分層抽樣（Stratified Sampling）並考慮時間區間，能更準確地反映真實世界的數據分布並提升模型穩健性。"
            },
            {
                category: "科目一",
                question: "某公司建置基於檢索增強生成（RAG）的知識查詢系統，需同時兼顧查詢效能與資料的即時更新。近期發現回應內容偶爾過時，且每次更新文件都需完整重建索引，導致系統在更新期間無法服務。若要解決此問題並提升整體穩健性，下列哪項做法最適合？",
                options: [
                    "調整生成模型的回應隨機性參數，以降低答案偏差並提升一致性",
                    "提升檢索與索引的運算效能，以縮短查詢與更新所需時間",
                    "採用索引的增量或分段更新方式，使新資料能即時納入而不需全部重建",
                    "建立常見問題的標準答案集，透過快速檢索回應以降低模型負擔"
                ],
                correct: 2,
                explanation: "RAG 系統若每次更新都需完整重建索引，會導致服務中斷與即時性不足。採用「增量更新（Incremental Update）」或「分段更新」可以在不停止服務的情況下，僅針對新文件建立索引，解決即時更新與服務可用性的問題。"
            },
            {
                category: "科目一",
                question: "關於監督式學習（Supervised Learning）與非監督式學習（Unsupervised Learning）的目標，下列敘述何者錯誤？\n1. 非監督式學習的核心在於發掘資料內在結構，例如分群、關聯規則與降維，而不依賴外部標籤。\n2. 監督式學習的典型應用為分類與迴歸，通常不適合應用於異常偵測任務。\n3. 非監督式學習若搭配少量標註資料，即會完全轉化為監督式學習。\n4. 監督式學習仰賴已標註的資料集，透過最小化輸出與真實標籤之間的差距，學習輸入與目標之間的對應函數。\n5. 所有監督式學習任務都必須要有大量完整標註資料，否則無法進行任何有效的模型訓練。\n6. 非監督式學習不需要目標變數，僅透過輸入資料本身的特徵分布進行模式學習。",
                options: [
                    "3、5、6",
                    "1、4、6",
                    "2、4、6",
                    "2、3、5"
                ],
                correct: 3,
                explanation: "錯誤的敘述包含：(2) 監督式學習亦可用於異常偵測；(3) 搭配少量標註應稱為半監督式學習；(5) 並非所有任務都必須大量標註資料，可透過微調或遷移學習處理。"
            },
            {
                category: "科目一",
                question: "一家旅遊平台希望建立模型，預測顧客下次是否會再次透過該平台訂房。資料包含：顧客 ID、年齡、旅遊次數、平均花費金額、主要交通方式（火車／飛機／自駕／公車）、會員等級（普通／進階／白金）、是否為海外旅遊等。下列哪一種特徵工程方法最適合處理「主要交通方式」欄位？",
                options: [
                    "布林轉換 (Boolean Conversion)",
                    "序數編碼 (Ordinal Encoding)",
                    "數值標準化 (Numerical Standardization)",
                    "One-hot 編碼 (One-hot Encoding)"
                ],
                correct: 3,
                explanation: "「主要交通方式」屬於名目型資料（Nominal Data），類別之間沒有邏輯上的順序或大小之分。在類別數量不多的情況下，使用 One-hot 編碼能有效地將其轉換為數值向量供模型學習，且不會引入錯誤的順序關係。"
            },
            {
                category: "科目一",
                question: "某大型零售企業準備將商品推薦模型上線，專案團隊在檢視訓練資料時，發現部分商品類別（例如高價商品）樣本數量極少，而多數樣本集中於低價商品。若此不平衡問題未妥善處理，下列何種狀況最可能在實際推薦結果中發生？",
                options: ["模型由於類別分布不均，難以建立有效的線性分離邊界，進而無法收斂","模型學到的決策邊界主要由多數類別主導，忽視了稀有類別，造成該類別的召回率（Recall）大幅降低","模型過度聚焦於稀有類別樣本，導致對多數類別的預測能力下降，整體效能受損","模型在預測時傾向輸出稀有類別，導致雖能捕捉到少數樣本，但精確率（Precision）顯著下降"],
                correct: 0,
                explanation: ""
            },
            {
                category: "科目一",
                question: "某醫院計畫開發住院日數預測模型，以協助病房調度。多數病人的住院日數集中在3–7天，但仍有少數重症患者因治療需求而住院日數明顯偏長。醫院希望採用一種合適的評估方式，既能兼顧大部分病人的預測準確度，也能確保對重症個案的預測維持穩健。下列哪一種方法最符合此需求？",
                options: ["在模型檢核時，同時呈現平均絕對誤差（MAE）與重症子群的誤差指標","僅針對一般病人樣本進行交叉驗證，以避免重症個案拉高誤差","將所有病人的住院日數進行標準化處理，以減少數值範圍差異的影響","只採用單一的整體決定係數 (R²) 作為模型優劣的判斷依據"],
                correct: 0,
                explanation: ""
            },
            {
                category: "科目一",
                question: "某公司欲建立員工離職風險預測模型，資料集中包含「年度績效分數」、「平均每月加班時數」、「年齡」等數值型特徵。由於各特徵的數值範圍差異極大（例如績效分數 1 - 5、加班時數 0 - 80、年齡 20 - 65），若直接輸入至使用梯度下降的邏輯迴歸 (Logistic Regression) 模型，可能導致模型收斂緩慢或權重偏斜。為提升模型訓練效率與準確度，下列哪一種特徵工程方法最適合應用於這些數值特徵？",
                options: [
                    "布林轉換 (Boolean Conversion)",
                    "時間序列分解 (Time Series Decomposition)",
                    "One-hot 編碼 (One-hot Encoding)",
                    "數值標準化 (Numerical Standardization)"
                ],
                correct: 3,
                explanation: "當數值型特徵的量綱（單位與範圍）差異較大時，會導致梯度下降法在更新參數時產生不穩定的震盪，影響收斂速度。透過「數值標準化（如 Z-score 或 Min-Max Scaling）」將數據縮放到相同的尺度，能有效提升邏輯迴歸等基於梯度演算法的訓練效率。"
            },
            {
                category: "科目一",
                question: "一家跨國醫療研究機構希望利用各地醫院的病患資料，建立一個能夠預測疾病早期風險的機器學習模型。由於各國法規限制，病患的原始資料無法集中到單一伺服器。在此情境下，下列哪一種方法最能同時滿足「各醫院保留資料不外流」與「模型仍能跨院學習」的需求？",
                options: ["聯邦學習（Federated Learning）","資料匿名化（Data Anonymization）","差分隱私（Differential Privacy）","交叉驗證（Cross-validation）"],
                correct: 0,
                explanation: ""
            },
            {
                category: "科目一",
                question: "某醫院研究團隊蒐集了大量病患的「收縮壓」數據，經檢驗後顯示此數值大致呈現常態分布。在進行後續模型分析前，研究人員希望妥善處理可能存在的極端血壓數值。下列哪一種做法最為合適？",
                options: ["透過Z分數（Z-score）或標準差範圍檢測異常值，並依研究需求決定是否調整或移除","將所有極端偏高或偏低的血壓數據直接刪除，以保留最具代表性的病患樣本","使用對數轉換（Log Transformation），將數據壓縮至更接近常態，以降低極端值的影響","將檢測到的離群值以Label Encoding編碼，轉換為序號標籤以避免影響原始分布"],
                correct: 0,
                explanation: ""
            },
            {
                category: "科目一",
                question: "某電商公司想預測用戶是否會購買特定商品，資料中包含多種用戶屬性與行為特徵。分析師希望選出對購買結果最有預測價值的特徵，以提升模型效能。下列哪一種描述最符合監督式特徵選擇（Supervised Feature Selection）的概念？",
                options: [
                    "根據特徵的整體分布、變異度或資訊量進行篩選，而不直接參考目標變數",
                    "評估每個特徵與目標變數之間的相關性，選擇對預測結果貢獻最大的特徵",
                    "使用模型評估特徵對預測結果的重要性，並保留對目標變數影響較大的欄位",
                    "將特徵透過降維方法（如 PCA）轉換為新特徵，再用於模型訓練"
                ],
                correct: 1,
                explanation: "監督式特徵選擇的核心在於「參考目標變數」。透過評估特徵與目標標籤（是否購買）之間的關聯程度（如相關係數、互資訊等），挑選出最具鑑別力的特徵，這與不看標籤的非監督式篩選（如 A、D）有本質上的區別。"
            },
            {
                category: "科目一",
                question: "在訓練神經網路時，為了提升模型收斂速度與穩定性，避免梯度消失或梯度爆炸，下列哪一種做法最常被使用？",
                options: [
                    "對輸入資料進行隨機旋轉或水平翻轉，以增加資料多樣性",
                    "選用 ReLU 或其變體作為隱藏層的啟動函數，以改善梯度傳播",
                    "減少樣本量提升訓練速度",
                    "對目標變數或特徵進行標準化"
                ],
                correct: 1,
                explanation: "ReLU（Rectified Linear Unit）啟動函數在正值區域的導數恆為 1，能有效緩解傳統 Sigmoid 或 Tanh 函數在深層網路中容易產生的梯度消失（Vanishing Gradient）問題，從而加速模型收斂並提升訓練穩定性。"
            },
            {
                category: "科目一",
                question: "若希望檢視某一連續型數據的分布情形（如集中程度、偏態或是否呈現多峰），下列哪一種應用情境最適合使用直方圖（Histogram）來進行分析？",
                options: [
                    "探討顧客年齡資料的整體分布特徵，並檢視是否存在異常集中或分散現象",
                    "比較不同商品在各月份的銷售額變化趨勢，以觀察季節性波動",
                    "追蹤公司近一年營收的時間序列變化，以了解整體成長趨勢",
                    "檢視產品價格與月銷售量之間的關聯性，以評估是否具線性相關"
                ],
                correct: 0,
                explanation: "直方圖（Histogram）是統計學中觀察「連續型變數」次數分布最常用的工具，能直觀呈現數據的集中趨勢、偏態（Skewness）與峰度。其他選項較適合的圖表為：(B)(C) 折線圖、(D) 散佈圖。"
            },
            {
                category: "科目一",
                question: "下列何者並非我國數位發展部 AI 產品與評測中心在評估大型語言模型安全性時，所指出的常見使用指標？",
                options: [
                    "資料複雜性",
                    "事實正確性",
                    "偏見與歧視",
                    "惡意與濫用可能性"
                ],
                correct: 0,
                explanation: "數位發展部 AI 評測中心針對 LLM 安全性的評測指標通常聚焦於模型產出的內容品質與潛在風險，如事實正確性（Hallucination 問題）、公平性（避免偏見與歧視）以及安全性（防範惡意與濫用）。「資料複雜性」多用於描述訓練數據集的特徵，而非直接衡量模型安全性的常見指標。"
            },
            {
                category: "科目一",
                question: "某雲端服務公司計畫將大型語言模型部署於線上系統，並以批次推論（Batch Inference）方式處理每日上百萬筆用戶請求。專案團隊在評估可能遇到的挑戰時，下列哪一項通常不會被視為批次推論階段的主要難題？",
                options: ["如何確保訓練語料的涵蓋性與標註品質，以避免模型偏差影響輸出","當批次規模增大時，如何降低推論延遲並保持即時回應能力","在推論過程中，有效管理與分配龐大的輸入資料量以避免資源壅塞","在叢集環境中精確安排推論任務，以提升GPU/TPU等硬體資源的利用率"],
                correct: 0,
                explanation: "在批次推論階段，主要關注的是如何有效處理大量資料、降低延遲、管理資源分配與任務排程。而訓練語料的品質問題屬於模型訓練階段需考量的議題，因此不屬於批次推論階段的主要難題。"
            },
            {
                category: "科目二",
                question: "在 Low Code 平台的開發應用設計中，關於「模型 (Model)」，下列敘述何者最符合實際情況？",
                options: [
                    "模型僅扮演設計視覺化的輔助工具，對應用邏輯的影響有限；",
                    "模型是用來抽象描述資料結構、業務流程與介面邏輯的核心元素，影響應用的設計與維護；",
                    "模型僅依循 UML (Unified Modeling Language) 等傳統建模方式，缺乏針對 Low Code 環境的延展性；",
                    "模型在 Low Code 平台中已被自動程式碼生成全面取代，實際價值有限"
                ],
                correct: 1,
                explanation: "在低程式碼（Low-Code）開發中，模型是核心驅動要素。它不僅是視覺輔助，更是定義資料、流程與邏輯的基礎，直接決定了應用程式的架構與後續維護的便利性，而非被自動代碼生成完全取代。"
            },
            {
                category: "科目二",
                question: "企業在導入生成式 AI 平台時，往往需要利用分散於不同部門或機構中的大量敏感文本資料。若希望在確保隱私的前提下，仍能讓模型持續優化並降低資料外洩風險，下列哪一種方法最適合？",
                options: [
                    "同態加密 (Homomorphic Encryption)",
                    "安全多方計算 (Secure Multi-party Computation)",
                    "零知識證明 (Zero-knowledge Proofs)",
                    "聯邦學習 (Federated Learning)"
                ],
                correct: 3,
                explanation: "聯邦學習允許在不移動原始敏感資料的情況下，讓各節點（部門或機構）在本地訓練模型並僅上傳參數更新，有效達成資料隱私保護與模型持續優化的平衡。"
            },
            {
                category: "科目二",
                question: "某企業利用 No Code/Low Code 平台開發內部營運系統。為確保系統在跨部門流程與外部服務整合下仍具良好的可測試性 (Testability)，下列哪一項作法最為合適？",
                options: [
                    "依賴 No Code/Low Code 平台提供的即時預覽與基本單元測試功能，快速驗證常見流程",
                    "導入可重複執行的自動化測試流程，並透過 API 或服務虛擬化進行模組化驗證",
                    "將測試聚焦於使用者介面互動與操作流程驗證，檢查系統表面功能",
                    "依靠使用者回饋與正式上線後的監控資料，作為修正依據"
                ],
                correct: 1,
                explanation: "對於複雜的跨部門流程與整合系統，單純的預覽或界面測試不足以確保穩定性。導入自動化測試並結合 API 服務虛擬化，能更深度地進行模組化驗證，提升系統的可測試性與可靠度。"
            },
            {
                category: "科目二",
                question: "某社交平台嘗試結合自動提示工程 (Automatic Prompt Engineer, APE) 與圖提示 (Graph Prompting)，讓 AI 協助分析使用者之間的互動關係。在這個過程中，下列何者為最可能遇到的挑戰？",
                options: [
                    "圖結構轉換為文字提示時，可能導致部分關聯資訊遺失",
                    "APE 在圖資料上無法產生任何提示內容",
                    "圖轉文字後能完整保留所有上下文，對推理不造成影響",
                    "Graph Prompting 僅能處理線性路徑，限制多分支探索"
                ],
                correct: 0,
                explanation: "圖資料（Graph Data）具有高維度的拓撲結構與複雜節點關係，當為了配合大語言模型（LLM）的輸入而將其轉換為線性文字描述（Textualization）時，往往難以完全保留原有的空間聯通性與結構權重，容易造成關鍵關聯資訊的遺失。"
            },
            {
                category: "科目二",
                question: "在超長上下文任務中使用自動提示工程 (Automatic Prompt Engineer, APE) 時，可能面臨的最大限制是什麼？",
                options: [
                    "迭代優化難以因應上下文的不斷變動，導致調整失效；",
                    "模型的記憶容量有限，無法完整保留所有長篇資訊；",
                    "提示內容難以有效分解，無法支援複雜任務拆解；",
                    "回饋機制通常僅針對局部片段，難以全面評估最終輸出品質"
                ],
                correct: 3,
                explanation: "在超長文本中，APE 的自動評分與回饋機制往往受限於計算資源或視窗長度，只能針對部分片段給予回饋，導致優化過程缺乏對全文連貫性或最終結果的全局評估。"
            },
            {
                category: "科目二",
                question: "某設計團隊計畫在短時間內完成一款行動應用程式，必須同時達到高度個人化體驗、快速生成介面與行銷內容自動產出等需求。若結合 No Code/Low Code 平台與生成式 AI 技術，以下哪一種整合策略最能符合目標？",
                options: [
                    "使用生成式 AI 自動產生 API 呼叫與元件配置，並由開發者手動整合至 No Code 平台流程",
                    "透過生成式 AI 在 No Code 平台中自動建立介面模板，並結合使用者數據即時生成個人化功能與行銷推播內容",
                    "在 No Code 平台中導入生成式 AI，快速建立跨專案可重用的通用模組，專注於提升開發速度",
                    "在 No Code 平台中完全依賴生成式 AI 自動產生所有應用功能與流程，不經人工設計或驗證"
                ],
                correct: 1,
                explanation: "此策略充分利用生成式 AI 的自動化設計能力與內容產出優勢，並結合 No Code 平台的快速開發特性，能精準對應「高度個人化」與「行銷內容自動化」的目標。"
            },
            {
                category: "科目二",
                question: "某團隊希望讓 AI 自動查詢 GitHub 上的程式碼庫，並生成摘要給使用者參考。開發者決定透過 Model Context Protocol (MCP) 來實現，AI 需先發出請求，再經由 MCP 架構逐步完成查詢與回傳。在此情境下，MCP 運作流程的正確順序為何？",
                options: [
                    "MCP Server → AI Host → MCP Client → 資料查詢 → 結果回傳 AI Host",
                    "MCP Client → AI Host → MCP Server → 資料查詢 → 結果回傳 AI Host",
                    "AI Host → MCP Client → MCP Server → 資料查詢 → 結果回傳 AI Host",
                    "AI Host → MCP Server → MCP Client → 資料查詢 → 結果回傳 AI Host"
                ],
                correct: 2,
                explanation: "MCP 標準流程中，由 AI 主機 (AI Host) 發起請求，透過客戶端 (MCP Client) 轉接至伺服器端 (MCP Server) 執行實際的資料操作（如 GitHub 查詢），最後再依原路徑回傳結果。"
            },
            {
                category: "科目二",
                question: "在 Agent-to-Agent (A2A) 架構中，不同代理人之間會分工合作。一般而言，下列敘述何者最符合 Client Agent 與 Remote Agent 的互動流程？",
                options: [
                    "Remote Agent 主動分派任務給 Client Agent",
                    "由人工事先設定 Client Agent 與 Remote Agent 處理任務的先後順序",
                    "Client Agent 發起任務，Remote Agent 執行並回傳結果",
                    "Client Agent 與 Remote Agent 同時處理任務並同步處理結果"
                ],
                correct: 2,
                explanation: "在 A2A 架構中，通常由直接面對用戶或主控流程的 Client Agent 定義需求並將任務委派給具備特定能力的 Remote Agent，後者完成後再將輸出交回。"
            },
            {
                category: "科目二",
                question: "在導入生成式 AI 的應用規劃中，上下文工程 (Context Engineering) 的核心目的為何？",
                options: [
                    "縮短模型訓練時間",
                    "優化提示與上下文",
                    "增加模型參數數量",
                    "優化 Fine-tuning 正確率"
                ],
                correct: 1,
                explanation: "上下文工程主要關注如何精準篩選、組織提供給模型的輸入資訊，透過優化 Prompt 與相關背景資料（Context），使模型在推理時能產出更符合需求的結果。"
            },
            {
                category: "科目二",
                question: "某公司在導入生成式 AI 協助撰寫內部報告時，測試人員刻意在輸入的上下文內容中放入互相矛盾的資訊（例如：同一位員工在不同段落被描述為「入職三年」與「入職五年」）。在這種情況下，最常見的模型行為會是什麼？",
                options: [
                    "永遠選擇第一段資訊作為答案依據",
                    "可能生成幻覺或隨機採信其中一方的內容",
                    "拒絕回答，並要求提供更一致的輸入",
                    "自動判斷並只選擇正確的資訊"
                ],
                correct: 1,
                explanation: "當模型面臨邏輯衝突的上下文時，無法自主判斷現實真偽，容易因機率機制導致「幻覺」（Hallucination）或隨機挑選資訊，進而產出不準確或自我矛盾的報告。"
            },
            {
                category: "科目二",
                question: "Agentic AI 在解決方案圖譜 (Solution Graph) 上尋找最佳解決路徑時，通常會使用什麼樣的搜尋策略？",
                options: [
                    "使用廣度優先、深度優先或最佳優先等演算法進行探索",
                    "每一步都隨機選擇動作，反覆嘗試直到找到一條可行路徑",
                    "只執行事先假定的一條路徑，失敗就停止",
                    "完全依靠 LLM 一次性推斷最優完整路徑"
                ],
                correct: 0,
                explanation: "Agentic AI 在處理複雜問題時，會將其視為圖形搜尋問題，利用經典的搜尋演算法（如 BFS、DFS 或啟發式的 Best-first search）在多種可能的步驟中尋找最佳路徑。"
            },
            {
                category: "科目二",
                question: "某企業考慮將開源大型語言模型（GPT-OSS）自行部署在本地伺服器，以取代雲端服務。下列何者最能代表本地部署對企業的實際好處？",
                options: [
                    "可以達到無運算成本，因為本地部署模型不會產生額外的資源消耗",
                    "模型的預測能力會比在雲端運行時更精度，因為本地環境更加可靠",
                    "可確保輸入模型的敏感資料不會傳輸給第三方，提升資料隱私和自主控制",
                    "以上皆是"
                ],
                correct: 2,
                explanation: "本地部署（On-premise）最核心的價值在於資料安全與隱私控管，企業能完全掌控敏感資料的流向，避免機密在雲端傳輸或被第三方模型廠商儲存。"
            },
            {
                category: "科目二",
                question: "關於 GitHub Copilot，下列敘述何者正確？",
                options: [
                    "GitHub Copilot 基於程式碼片段查詢工具，透過後端搜尋大型程式碼資料庫提供建議",
                    "GitHub Copilot 僅適用於 GitHub 上的開源專案，無法在私有程式碼庫或本地環境中提供程式碼補全建議",
                    "GitHub Copilot 利用靜態分析技術分析程式碼，根據邏輯流程推導下一步應寫的程式碼",
                    "GitHub Copilot 由 OpenAI 的 Codex 模型提供技術支援，可即時在開發者編輯程式碼時給出整行或整個函式建議"
                ],
                correct: 3,
                explanation: "GitHub Copilot 核心技術源於 OpenAI 的 Codex 模型，它能根據上下文預測開發者的意圖，並即時產出高品質的程式碼補全建議。"
            },
            {
                category: "科目二",
                question: "某電商公司導入 Agentic AI 來處理客服工作。測試發現 Agent 在回答產品 FAQ 時經常出錯，且無法幫客戶修改訂單。這種情況最可能是因為缺少下列哪兩項工具或技術？",
                options: [
                    "API 調用 (API Calling) + 任務規劃器 (Task Planner)",
                    "向量資料庫檢索 (Vector Retrieval) + API 調用 (API Calling)",
                    "向量資料庫檢索 (Vector Retrieval) + 任務規劃器 (Task Planner)",
                    "任務規劃器 (Task Planner) + 溫度參數 (Temperature) 設定"
                ],
                correct: 1,
                explanation: "回答 FAQ 出錯代表缺乏精準的知識檢索（需向量資料庫支援 RAG），而無法修改訂單代表 Agent 沒有權限或機制與後端系統互動（需透過 API 調用執行動作）。"
            },
            {
                category: "科目二",
                question: "某客服自動回應系統希望根據不同客戶群體調整回覆風格。在兼顧即時性與效果的前提下，下列哪一種方案最適合？",
                options: [
                    "直接微調預訓練模型針對每個客戶群體分別訓練不同風格模型",
                    "利用控制變量 (Control Tokens) 或風格標籤在同一模型內動態調整風格",
                    "利用生成對抗網路 (GAN) 生成不同風格文本，並透過人工篩選最終答案",
                    "採用規則式替換方法，替換回覆詞彙以符合不同風格要求"
                ],
                correct: 1,
                explanation: "使用控制標籤（Control Tokens）是在單一模型中實現多樣化輸出的高效做法，相比於微調多個獨立模型，它更具成本效益且能即時切換風格。"
            },
            {
                category: "科目二",
                question: "在建置多代理大型語言模型 (Multi-agent LLMs) 系統時，如果沒有清楚定義每個代理的任務啟動條件和角色分工，最可能出現什麼問題？",
                options: [
                    "回覆內容前後不連貫，系統邏輯斷裂",
                    "不同代理的答案互相衝突，無法判斷最終決策",
                    "系統陷入無限對話循環，導致資源耗盡",
                    "多個代理重複做同樣的任務，造成效率低落"
                ],
                correct: 3,
                explanation: "當代理人（Agent）之間的角色分工不明確或啟動觸發機制設計不良時，容易發生代理人 A 呼叫 B，B 又呼叫 A 的狀況，進而導致無限循環並耗盡運算資源。"
            },
            {
                category: "科目二",
                question: "某公司部署結合 Fine-tuning 與檢索增強生成 (RAG) 的語言模型系統作為內部文件助理。系統需同時確保回覆語氣一致、能即時查詢每日新增文件、維持效能穩定，並避免頻繁重新訓練。在長期維護與效能平衡下，下列哪一種策略最合適？",
                options: [
                    "每週重新 Fine-tune 模型，將新文件整合進模型知識，逐步取代 RAG 模組",
                    "完全依靠基礎模型與 RAG，不進行 Fine-tune，僅透過提示設計控制語氣",
                    "每日進行增量 Fine-tune，讓模型即時學習新文件內容，避免依賴檢索",
                    "保留語氣相關 Fine-tuning，僅透過檢索系統更新文件內容，不頻繁改動模型"
                ],
                correct: 3,
                explanation: "Fine-tuning 適合用來定調模型的行為與語氣，而 RAG 則適合處理頻繁更新的動態資料（如每日文件）。將兩者分工能兼顧表現一致性與維護成本。"
            },
            {
                category: "科目二",
                question: "某客服系統在回覆「訂單取消政策」時，即使生成溫度固定為 0.6，回覆品質仍常出現差異。調查顯示，檢索到的政策內容有時是最新版本，有時則是過時文件，此外 Prompt 約束不足，微調語料也有模糊描述。若要優先改善品質波動，應先解決下列哪一項問題？",
                options: [
                    "調整溫度參數，降低生成隨機性",
                    "加強 Prompt 設計，限制模型表達方式",
                    "優化微調語料，減少含糊描述",
                    "提升檢索系統品質，確保取得的政策內容正確且最新"
                ],
                correct: 3,
                explanation: "RAG 系統的品質高度依賴檢索結果。若檢索到錯誤或過時的原始文件，無論模型如何優化，產出的答案必然會出現錯誤，因此提升檢索內容的正確性是首要任務。"
            },
            {
                category: "科目二",
                question: "某醫院導入了一套智慧系統，由三個模組構成：語音辨識 (ASR) → 語言模型生成 (LLM) → 查詢醫療資料庫 API。近期發現部分查詢結果錯誤，例如醫師詢問「術後復健流程」時，系統卻誤判為要查詢「術前注意事項」，因此查詢到錯誤的文件。經檢查已排除語音辨識的錯誤，下列何者最可能是造成查詢錯誤的來源？",
                options: [
                    "醫療資料庫 API 對應規則設計不清，造成意圖映射模糊",
                    "LLM 的 Prompt 缺乏明確指示，導致語意分類判斷錯誤",
                    "查詢 API 回傳速度過慢，影響系統處理正確性",
                    "LLM 未經醫療領域微調，難以正確理解專業性詞彙"
                ],
                correct: 1,
                explanation: "題目指出 ASR 沒錯，但 LLM 誤判了查詢意圖。這通常是因為 Prompt 的分類指令不夠精確，導致模型無法將醫師的語意正確映射到對應的查詢類別。"
            },
            {
                category: "科目二",
                question: "某醫院正在規劃一個 AI 專案，目的是協助醫師從胸腔 X 光影像中判斷是否存在肺炎徵兆，團隊卻誤將生成式 AI 模型運用於影像診斷。下列哪一項最可能成為主要風險？",
                options: [
                    "模型在生成報告時語句流暢，但僅在文字表達上有差異，對診斷結果沒有重大影響",
                    "模型若資料不足，僅會降低生成報告的完整性，而非影響判斷病灶的正確性",
                    "模型偏向生成內容而非分類，但此差異僅影響效率，不會造成誤診風險",
                    "模型可能生成與實際影像不符的診斷結論，導致誤判並引發醫療與法律風險"
                ],
                correct: 3,
                explanation: "生成式 AI（如 LLM）本質上是處理文字序列，強行將其用於精密的影像診斷容易產出看似專業但與影像事實不符的「幻覺」結論，將導致嚴重的誤診風險。"
            },
            {
                category: "科目二",
                question: "某公司開發的智慧車載語音助理，可透過語音辨識 (ASR) 辨識駕駛語音，再由 LLM 生成回答並查詢車載 API。測試中發現：ASR 對汽車專業術語辨識錯誤率高；LLM 的回覆常不精確；系統回覆延遲雖存在但仍可接受。若目標是「優先提升準確性與回答品質」，下列改進步驟的最合理執行順序為何？\n1. 擴充並標註汽車領域語音資料，微調 ASR 模型\n2. 微調 LLM 並加入檢索增強 (RAG)\n3. 優化系統架構，引入批次推論降低延遲\n4. 動態調整生成溫度，平衡準確度與多樣性",
                options: [
                    "1→2→4→3",
                    "2→1→3→4",
                    "1→3→2→4",
                    "3→1→2→4"
                ],
                correct: 0,
                explanation: "優化應由底層基礎開始：先提升 ASR 辨識準確率，再強化 LLM 生成品質（透過 RAG 或微調），接著微調生成參數以平衡品質，最後在準確性達標後才優化延遲架構。"
            },
            {
                category: "科目二",
                question: "一家顧問公司使用生成式 AI 協助撰寫數據分析報告。雖然模型在測試中表現優異，但其生成的報告多半僅遵循固定段落結構，替換數值或關鍵詞即可完成，卻未能展現針對不同專案的多樣化推理與分析。下列何者為造成這種現象的最合理解釋？",
                options: [
                    "模型在生成過程中缺乏對字體與排版的優化能力，因此無法展現分析邏輯",
                    "測試資料涵蓋過多統計圖表，導致模型無法專注於文字內容的多樣化表達",
                    "模型過度依賴訓練語料中的常見報告範式，導致生成結果以樣板化結構取代真正的推理",
                    "模型因無法正確辨識報告中的頁碼與標題層級，才出現樣板化的結果"
                ],
                correct: 2,
                explanation: "生成式模型傾向於學習訓練數據中的統計規律。若訓練數據包含大量格式固定的報告，模型會產生「過擬合」於樣板結構的現象，導致輸出缺乏深度的多樣化分析。"
            },
            {
                category: "科目二",
                question: "在應用零樣本提示 (Zero-Shot Prompting) 時，下列哪一種情境最可能因缺乏示範而失敗，出現語意錯誤或結構錯誤的輸出？",
                options: [
                    "要求模型判斷一段影評文字的情感傾向",
                    "要求模型將一段新聞摘要濃縮為一句話",
                    "要求模型將一段繁體中文翻譯成英文",
                    "要求模型從表格中擷取所有城市的最高氣溫"
                ],
                correct: 3,
                explanation: "結構化數據提取（如表格資訊）相較於情感分析或翻譯，更依賴於對特定格式與欄位關係的精確理解。在沒有範例引導的情況下，模型較難保證提取內容的結構正確性。"
            },
            {
                category: "科目二",
                question: "某保險公司計畫導入生成式 AI 的內部合約查詢系統，協助業務員與法務部門快速解讀保單條款與理賠規範。高層特別強調客戶資料隱私與合規風險控管，即使需要投入較多資源，也必須確保資料不會外洩。在此情況下，下列哪一種策略最符合公司的資料安全與合規優先考量？",
                options: [
                    "導入開源模型並由 IT 團隊自建，後續再逐步補強隱私與合規控管",
                    "在需求確認階段即納入法遵與稽核單位，設定準確率 KPI，並透過 MVP 驗證成效",
                    "優先使用雲端大型 API 模型快速部署，並根據使用數據持續調整",
                    "投入資源自訓並私有化部署 LLM，並同步建立自動化風控機制"
                ],
                correct: 3,
                explanation: "在極度要求資料隱私的場景下，私有化部署（On-premise）是最佳選擇，能確保敏感的合約與保單資料完全不離開企業內網，從物理上根絕第三方外洩風險。"
            },
            {
                category: "科目二",
                question: "某新創公司開發一套圖像描述生成系統，能根據輸入的照片自動產生說明文字。為了讓產生的描述文字能與圖片資訊精準對應，下列哪一種設計思路最關鍵？",
                options: [
                    "強化語言模型的句法與流暢性，確保生成文字更自然易讀",
                    "在生成過程中結合圖片特徵與語言建模，讓模型同時利用影像內容與文字資訊",
                    "調整生成策略 (如 Beam Search 或溫度參數)，以提升輸出文字的合理性",
                    "專注於文字序列上下文的建模，只提升文字間的連貫性"
                ],
                correct: 1,
                explanation: "圖像描述（Image Captioning）的核心技術在於跨模態對齊。系統必須能夠將提取的圖像特徵與語言生成模型融合，使模型在生成每個詞時都能參考圖像內容。"
            },
            {
                category: "科目二",
                question: "某電商平台希望生成的商品描述在風格與用詞上保持一致性，但不需要新增專業知識。下列哪種方法最適合？",
                options: [
                    "擴充語料庫並微調模型，使風格統一",
                    "增加提示詞複雜度，引導模型風格一致",
                    "降低生成溫度，以減少隨機性並提升風格一致性",
                    "使用全連接神經網路對生成結果後期篩選"
                ],
                correct: 2,
                explanation: "溫度參數（Temperature）控制生成的隨機性。降低溫度會使模型更傾向選擇機率最高的詞彙，進而產生更穩定、風格更趨一致且不偏離預期風格的結果。"
            },
            {
                category: "科目二",
                question: "某企業已建置 AI 語音記錄系統，並希望整合生成式 AI 進行「會議即時摘要」功能，下列哪一種策略最能提升摘要的語意品質與使用價值？",
                options: [
                    "使用語音轉文字模型即時輸出逐字稿並轉入 GPT 摘要",
                    "將語音逐段切分並建立關鍵字索引，以利摘要模型從中擷取核心內容生成會議重點",
                    "將語音轉文字後標註發言角色與主題邊界，結合語意分群進行動態摘要",
                    "將所有語音內容儲存為完整紀錄，提供事後人工摘要比對用"
                ],
                correct: 2,
                explanation: "摘要的品質取決於對對話結構的理解。透過發言人辨識與主題切分，能為 AI 提供更清晰的上下文資訊，使摘要能準確歸納不同人的立場與會議轉折。"
            },
            {
                category: "科目二",
                question: "某公司正在開發一個智慧客服系統，負責回覆顧客關於退換貨、優惠活動與商品建議等問題。研發團隊嘗試使用不同的提示設計方式來提升模型效能。下列哪一個提示最符合「少樣本提示 (Few-Shot Prompting)」的設計原則？",
                options: [
                    "「請回答顧客詢問：如何申請退貨？」",
                    "「以下是兩組客服對話範例，請依照相同風格回覆新的顧客問題」",
                    "「請逐步分析顧客投訴的原因，並依照推理過程生成合適回覆」",
                    "「請以正式的語氣回覆顧客的提問」"
                ],
                correct: 1,
                explanation: "少樣本提示（Few-Shot）的核心特徵是在提示詞中提供具體的輸入與輸出範例，引導模型模仿範例的邏輯或格式進行生成。"
            },
            {
                category: "科目二",
                question: "某投資公司導入生成式 AI，用於即時分析股市波動並提供市場背景資訊。若希望 AI 能兼顧「即時性」與「可靠性」。下列哪一項設計最能有效提升 AI 在即時股市分析上的表現？",
                options: [
                    "將 AI 系統連結至公司內部歷史交易資料庫，以便快速調用既有的案例參考",
                    "調整模型的回應邏輯，讓 AI 優先輸出最新市場行情，而不是完整背景分析",
                    "建立與外部即時行情來源同步的查詢模組，確保 AI 能即時擷取最新金融數據",
                    "增加訓練資料中模擬的金融危機與市場異常案例,以提升 AI 在特殊情境下的表現能力"
                ],
                correct: 2,
                explanation: "由於模型預訓練知識具備時效限制，對於股市這類動態數據，必須透過 RAG 檢索機制結合外部 API 獲取當前即時行情，方能提供可靠的分析報告。"
            },
            {
                category: "科目二",
                question: "某大型物流公司計畫導入 AI 系統，以改善客服與配送作業的效率。專案團隊規劃了以下四個步驟，請問正確的執行順序為何？\n1. 建立符合公司服務流程的 AI 對話邏輯與應答範本，確保顧客體驗一致\n2. 明確定義導入 AI 的目標並設定關鍵績效指標 (KPI)\n3. 蒐集與清理過往客服紀錄與配送相關資料，作為模型訓練素材\n4. 評估並選擇合適的 AI 技術供應商或開源方案，確立技術方向與架構",
                options: [
                    "2→3→4→1",
                    "3→2→1→4",
                    "2→1→3→4",
                    "1→4→3→2"
                ],
                correct: 0,
                explanation: "專案實施應遵循：先定義目標（KPI），隨後準備基礎數據（蒐集清理），再依需求評估技術架構，最後才是具體的業務邏輯設計與模型應用開發。"
            },
            {
                "category": "科目二",
                "question": "某跨國電商企業導入生成式AI，協助處理顧客服務請求，並根據顧客歷史訂單提供個人化建議。資安與法遵部門擔心AI在回覆時可能洩漏顧客個資，若要在導入初期優先避免觸法風險，下列哪一項措施最符合要求？",
                "options": [
                    "在加密環境下導入完整的顧客訂單與行為資料，並透過嚴格存取控管降低洩漏風險",
                    "實施資料最小化與去識別化，確保AI在訓練與生成過程中不直接處理或暴露敏感個資",
                    "強化模型的回覆審查流程，透過自動過濾與人工抽查結合，降低個資外洩的機率",
                    "設定AI的角色與回覆範圍，讓其專注於客服相關內容，避免回答其他敏感議題"
                ],
                "correct": 1,
                "explanation": "資料去識別化與最小化是保護隱私的最根本手段。透過在資料處理階段就移除或遮蓋敏感個資，可確保模型在生成過程中完全無法接觸到真實身分資訊，從源頭降低合規風險。"
            },
            {
                "category": "科目二",
                "question": "某國際銀行導入生成式AI，用於彙整不同國家金融監管機構的合規規範，建立跨國合規知識庫。由於各國條文表述方式不同，且監管要求具有高度專業性與隱含邏輯，若要確保知識庫在後續查詢與生成報告時能維持正確性與一致性，下列哪一項AI能力最為關鍵？",
                "options": [
                    "具備跨語言專業術語對齊與條文語意抽取能力，能正確辨識不同國家規範間的對應與差異",
                    "能自動最佳化文件檢索效率，縮短跨國法規查詢的延遲時間，提升合規部門使用體驗",
                    "能將合規文件轉換為多種輸出形式(如簡報、摘要或法規清單)，以符合不同決策層級需求",
                    "具備根據歷史案例生成合規解釋的能力，協助新進員工快速理解法規在實務上的應用"
                ],
                "correct": 0,
                "explanation": "跨國合規管理的核心在於準確理解不同語言環境下的專業術語與法律邏輯。只有具備強大的語意抽取與對齊能力，才能確保不同國家的規範在知識庫中被正確對接，避免因翻譯或理解偏差導致的合規風險。"
            },
            {
                "category": "科目二",
                "question": "在企業導入MLOps (Machine Learning Operations)的過程中，除了模型部署與維護挑戰外，仍可能面臨其他推動上的困難。下列何者為No Code 平台最能有效解決的挑戰？",
                "options": [
                    "自動化大量資料的標註與前處理，以降低數據準備成本",
                    "提升運算基礎設施的可擴展性，以因應大規模服務需求",
                    "透過可視化建模介面，降低技術門檻並促進跨部門協作",
                    "提供進階特徵工程能力，優化高維度數據的處理效率"
                ],
                "correct": 2,
                "explanation": "No Code 平台的主要價值在於民主化 AI 開發。透過圖形化、可視化的操作介面，非技術背景的業務人員也能參與模型構思與驗證，極大降低了溝通成本並加速跨部門協作流程。"
            },
            {
                "category": "科目二",
                "question": "某醫療機構計畫導入生成式AI協助撰寫病歷摘要。在技術測試階段，為確保系統能安全應用於臨床，最應優先關注下列哪一項指標？",
                "options": [
                    "資料儲存與存取架構的完整性，確保長期運作過程中的數據可追溯性",
                    "生成內容的醫療準確性與臨床一致性，避免出現錯誤或誤導性資訊",
                    "模型在不同病例語境下的泛化能力，確保不因個別樣本而偏差",
                    "系統回應時間的穩定性，以支援醫療場域中可能的即時需求"
                ],
                "correct": 1,
                "explanation": "在醫療場域，內容的準確性（Factual Accuracy）關乎生命安全。相較於系統速度或儲存架構，確保生成的病歷摘要不產生「幻覺」且符合臨床醫學事實是系統上線的最基本前置條件。"
            },
            {
                "category": "科目二",
                "question": "在即時客服系統的效能測試中，若針對延遲測試(Latency Testing)進行評估，下列哪一項指標最能反映系統是否符合用戶即時互動需求？",
                "options": [
                    "AI模型在同一分鐘內可完成的回覆訊息數量",
                    "客戶從輸入問題到收到第一個完整回應所需的時間",
                    "客服系統能連續提供服務的運行時長",
                    "AI產生回答時用詞的多樣性與表達創意程度"
                ],
                "correct": 1,
                "explanation": "即時互動體驗主要取決於回應速度。衡量從發送請求到接收首個回應的時間（Time to First Token 或 End-to-end Latency）是評估客服系統是否具有「即時性」的最直接標準。"
            },
            {
                "category": "科目二",
                "question": "某航空公司導入生成式AI聲控客服，提供航班與票務查詢。有人員透過惡意提示，試圖讓系統洩漏內部安檢流程。在此情境中，下列何者為降低提示攻擊(Prompt Injection)風險的最佳策略？",
                "options": [
                    "導入輸入檢測與回應審核流程，防止敏感指令被執行",
                    "限制AI 可回應的主題範圍，使系統僅回答非敏感的航班與票務查詢，避免處理內部或敏感流程資訊",
                    "隨機變化回覆內容，讓攻擊者難以預測回應行為以增加攻擊難度",
                    "擴充與更新航班與票務資料來源，以提升模型的知識正確性與覆蓋率"
                ],
                "correct": 0,
                "explanation": "應對提示注入攻擊的核心防禦手段是「過濾與審核」。透過對輸入端進行關鍵字攔截或意圖分析，以及對輸出端進行敏感資訊檢測，能有效封鎖試圖繞過系統限制的惡意指令。"
            },
            {
                "category": "科目二",
                "question": "在機器學習模型的實務應用中，常會出現數據漂移(Data Drift)的情況。此現象主要是指下列哪一種情況？",
                "options": [
                    "訓練時使用的資料分佈，與部署後實際輸入資料的統計特徵隨時間逐漸出現差異，導致模型表現衰退",
                    "在資料前處理過程中，因特徵刪減或缺失補值不當，造成樣本資訊量下降",
                    "模型對訓練數據擬合過度，在未知數據上泛化能力不足",
                    "後端資料庫因欄位定義或結構調整，導致特徵提取流程與原始設計不一致"
                ],
                "correct": 0,
                "explanation": "數據漂移是指生產環境中的資料特徵分佈隨時間發生變化，導致原本在訓練集上表現良好的模型因環境變遷而預測力下降。這是 MLOps 監控中最重要的環節之一。"
            },
            {
                "category": "科目二",
                "question": "某銀行導入生成式AI放貸審核系統，用於分析申貸人條件並生成初步審核意見。測試過程中發現，模型對不同族群的核准率存在顯著差異，可能引發演算法偏見問題。為降低此風險，下列哪一項措施最合適？",
                "options": [
                    "提升模型運算速度與效能，以確保在大量申請中快速回應",
                    "全面移除與申貸人身份相關的敏感屬性，避免模型因變數影響而產生偏差",
                    "導入資料與結果的公平性檢測流程，並依合規規範調整模型或決策邏輯",
                    "減少訓練樣本數量，降低偏見被放大的可能性"
                ],
                "correct": 2,
                "explanation": "單純移除敏感變數往往無法消除偏見，因為其他特徵（如郵遞區號）可能與敏感屬性具備高相關。建立公平性檢測與人工合規覆核機制，從決策邏輯層面進行校準才是負責住 AI 的作法。"
            },
            {
                "category": "科目二",
                "question": "在提示工程(Prompt Engineering)的應用中，Chain-of-Thought(CoT)與 Tree of Thoughts (ToT)各適用於不同的推理情境，情境一：電商公司開發客服助理，用來協助客戶查詢退款流程與相關規範；情境二：活動策劃團隊使用AI協助規劃多場跨部門行銷活動，需要同時考量預算、場地、時程與人力資源，並比較不同方案的可行性。請問這兩個情境分別最適合採用哪一種方法？",
                "options": [
                    "情境一採用CoT，情境二採用ToT",
                    "情境一採用ToT，情境二採用CoT",
                    "情境一與情境二都適合CoT",
                    "情境一與情境二都適合ToT"
                ],
                "correct": 0,
                "explanation": "CoT 適合處理單一、線性的邏輯推理（如依序解釋退款流程）；ToT 則適合處理具有多個決策分支、需比較不同路徑並回溯優化的複雜規劃任務（如跨部門行銷方案策劃）。"
            },
            {
                "category": "科目二",
                "question": "在生成式AI的提示工程中，Graph Prompting 在處理複雜關係資料時，為何通常比 Chain-of-Thought (CoT)更有效？",
                "options": [
                    "Graph Prompting 幾乎不需要推理，只依靠圖結構即可得出結論",
                    "Graph Prompting 僅需單次提示，即可避免多輪推理的誤差累積",
                    "Graph Prompting 的生成速度通常更快，因此效率更高",
                    "Graph Prompting 能捕捉非線性結構與上下文關聯，適合處理網絡化資訊"
                ],
                "correct": 3,
                "explanation": "CoT 主要處理序列化推理，而 Graph Prompting 能將節點間的拓撲結構與複雜關聯直接融入提示。對於網絡狀的資料（如知識圖譜、社交網絡），圖提示能更完整地保留非線性的語意關聯。"
            },
            {
                "category": "科目二",
                "question": "在少樣本提示(Few-shot Prompting)僅能提供1-2個範例的情況下，若遇到領域偏移(Domain Shift)，下列何者為模型最可能面臨的核心挑戰？",
                "options": [
                    "範例數量過少，無法涵蓋新領域的多樣性，導致模型泛化不足",
                    "範例表徵有限，模型容易依賴單一樣本特性而降低適應力",
                    "範例覆蓋不足，使模型難以抽取跨領域的穩定模式",
                    "範例資訊過於稀缺，模型缺乏應對不同輸入情境的能力"
                ],
                "correct": 0,
                "explanation": "當測試環境與訓練範例分佈不一致（領域偏移）時，僅有的少量範例無法提供足夠的統計特徵來覆蓋新領域的邊界情況，導致模型難以將範例中的規律泛化到新領域。"
            },
            {
                "category": "科目二",
                "question": "某金融機構導入檢索增強生成(Retrieval-Augmented Generation, RAG)模型，用於客服文件查詢與自動回覆。由於大型模型運算成本過高，若考慮引入知識蒸餾(Knowledge Distillation, KD)技術，下列何者為帶來的主要效益？",
                "options": [
                    "讓小型模型學習大型模型的知識，在降低運算成本的同時維持檢索與生成品質",
                    "只能應用於語音或影像辨識，無法提升文字檢索生成效能",
                    "因為RAG已有檢索機制，因此無需額外蒸餾知識",
                    "僅能依賴特定 API 供應商才能使用，無法在自建模型中實現"
                ],
                "correct": 0,
                "explanation": "知識蒸餾是將複雜大模型（Teacher）的推理能力轉移到輕量化小模型（Student）的技術。在 RAG 場景中，這能顯著降低推論延遲與伺服器成本，同時盡可能保留大模型的回答品質。"
            },
            {
                "category": "科目二",
                "question": "在評估大型語言模型，例如7B、13B、175B參數規模時，模型規模對基準測試(Benchmark)結果的影響，下列哪一種說法最為恰當？",
                "options": [
                    "小模型在正確調整下能超越大模型，因此模型大小並不重要",
                    "大模型在多數情境下表現較好，但在特定任務上略遜於小模型",
                    "模型規模與基準測試結果完全無關，影響主要來自測試設計",
                    "模型越大，Benchmark結果可能提升，但幅度取決於訓練數據品質與資源配置"
                ],
                "correct": 3,
                "explanation": "參數規模（Scaling Law）通常能提升模型上限，但效能的提升並非無限。最終表現高度依賴訓練資料的乾淨程度、語料覆蓋面以及訓練過程中的算力資源優化配置。"
            },
            {
                "category": "科目二",
                "question": "在AI應用設計中，Model Context Protocol (MCP)與檢索增強生成 (RAG)都能擴展模型的能力，但兩者的核心差異主要為下列何者？",
                "options": [
                    "MCP 擴展模型工具，但主要用於補足訓練資料不足",
                    "MCP能標準化連接資源,但仍需依賴向量資料庫",
                    "RAG 常用於擴展知識庫內容，而MCP更著重於動態工具與API 呼叫的整合",
                    "RAG透過統一協議，提升回答相關性"
                ],
                "correct": 2,
                "explanation": "RAG 的重點在於「檢索（Retrieval）」外部知識庫文件。而 MCP 是一種通用的協議架構，主要目的在於標準化 AI 與各種本地/遠端工具、資料庫及 API 的互動機制，強化 Agent 的執行能力。"
            },
            {
                "category": "科目二",
                "question": "下列哪一個資料集專門設計用於測試大型語言模型在多領域、多任務語言理解中，涵蓋人文、科學與社會科學等領域，而非專門用於數學推理或中文專業知識？",
                "options": [
                    "MMLU",
                    "GSM8K",
                    "MATH",
                    "C-Eval"
                ],
                "correct": 0,
                "explanation": "MMLU (Massive Multitask Language Understanding) 是目前最主流的綜合理解基準，涵蓋了 57 個學科領域；GSM8K 專注於數學，MATH 是進階數學，C-Eval 則是中文學科評測。"
            },
            {
                "category": "科目二",
                "question": "某智慧工廠導入生成式AI，協助產線工程師即時產生維修指引與操作建議。下列哪一項並非團隊在系統設計中加入Guardrails(防護機制)的主要目的？",
                "options": [
                    "檢查工程師輸入內容，避免觸發錯誤或危險需求",
                    "過濾與驗證AI輸出的維修指引，確保符合安全標準",
                    "確保生成的操作建議符合法規與產業安全規範",
                    "完整重建並追蹤 AI 模型的全部推理過程"
                ],
                "correct": 3,
                "explanation": "防護機制（Guardrails）的核心功能在於「安全防護與合規審核」，即對輸入/輸出進行過濾攔截。至於追蹤完整的推理過程（Reasoning Chain），通常屬於可解釋性（Explainability）或日誌審計的範疇。"
            },
            {
                "category": "科目二",
                "question": "某顧問公司導入生成式AI，協助團隊快速檢索並摘要長篇的法規文件。為了改善檢索結果常出現不相關或過於分散內容的問題，下列何者為團隊決定對文件進行文本切分(Chunking)的主要目的？",
                "options": [
                    "讓模型在回答時能加快推理速度",
                    "提高檢索相關性與降低長上下文噪音",
                    "降低系統記憶體和硬體資源的負擔",
                    "使模型在生成回覆時更具創造性與多樣化"
                ],
                "correct": 1,
                "explanation": "過長的文件包含過多無關資訊，直接檢索整篇文件會引入大量「噪音」。透過文本切分，能將文件拆成語意緊湊的片段，使向量檢索更精準，並降低無關資訊對生成結果的干擾。"
            },
            {
                "category": "科目二",
                "question": "某開發團隊在建置企業內部知識檢索系統時，選擇採用多向量檢索器 (Multi-vector Retriever)，下列何者為協助提升系統查詢的完整性與精準度的主要方式？",
                "options": [
                    "支援同時處理多種資訊表示，提升跨文本型態的檢索效果",
                    "透過多向量壓縮與共享權重方式，降低檢索過程的運算與儲存成本",
                    "以切分並過濾文件片段，減少上下文長度帶來的Token 負擔",
                    "透過調整生成階段的溫度參數，使模型在回覆時更穩定一致"
                ],
                "correct": 0,
                "explanation": "多向量檢索（Multi-vector Retrieval）允許為同一段文本儲存多個向量描述（如摘要向量、標題向量或不同角度的嵌入）。這能讓系統從不同語意維度捕捉與查詢的相關性，大幅提升檢索品質。"
            },
            {
                "category": "科目二",
                "question": "在Agentic AI 的架構中，解決方案圖譜(Solution Graph)常被用來輔助代理的任務執行，其主要作用為何？",
                "options": [
                    "透過圖形結構完全取代大型語言模型的推理，讓代理只依靠圖演算法完成任務",
                    "僅用於保存代理的輸出結果，方便後續檢視與審計，而不影響實際推理流程",
                    "將代理限制在既定流程內，避免其產生偏離設計腳本的行為",
                    "作為代理在執行過程中的參考框架，用於組織決策步驟並支援任務推理"
                ],
                "correct": 3,
                "explanation": "解決方案圖譜（Solution Graph）並非取代推理，而是為 Agent 提供結構化的路線圖。它將任務分解為節點，協助 Agent 管理執行狀態、記錄已嘗試的路徑，並在多步決策中進行路徑優化。"
            },
            {
                "category": "科目二",
                "question": "小明想開發一個部落格寫作工具，讓用戶輸入文章開頭後，系統自動幫忙寫出後續內容，例如輸入「今天去了台北木柵動物園...」，系統就能續寫。若要實現這樣的功能，最適合選擇下列哪一類任務？",
                "options": [
                    "序列到序列建模(Sequence-to-Sequence Modeling)，透過輸入序列產生新的輸出序列",
                    "遮罩語言建模(Masked Language Modeling)，補齊文字中缺失的詞語或片段",
                    "生成式語言建模(Text Generation)，依據上下文持續產生新的內容",
                    "文本分類(Text Classification)，針對輸入文本判斷情感、主題或標籤"
                ],
                "correct": 2,
                "explanation": "這種「由上文接續寫下文」的功能屬於生成式語言建模（如 GPT 系列常用的 Causal Language Modeling）。其訓練目標是預測下一個 Token，非常適合用於長文本創作與續寫任務。"
            },
            {
                category: "",
                question: "",
                options: ["","","",""],
                correct: 0,
                explanation: ""
            },
            {
                category: "",
                question: "",
                options: ["","","",""],
                correct: 0,
                explanation: ""
            },
            {
                category: "",
                question: "",
                options: ["","","",""],
                correct: 0,
                explanation: ""
            },
            {
                category: "",
                question: "",
                options: ["","","",""],
                correct: 0,
                explanation: ""
            },
            {
                category: "",
                question: "",
                options: ["","","",""],
                correct: 0,
                explanation: ""
            },
            {
                category: "",
                question: "",
                options: ["","","",""],
                correct: 0,
                explanation: ""
            },
            //////////
            // /////// 以下內容我不確定試科目一還是科目二
            {
                category: "",
                question: "生成對抗網路(GAN)是透過兩個神經網路的相互競爭來學習。其中，生成器(Generator)的目標是什麼?",
                options: ["生成與真實數據相似的新樣本","最小化模型在標記數據上的預測錯誤","準確地將輸入數據分類","將高維度數據壓縮到低維度空間"],
                correct: 0,
                explanation: "生成器的任務是學習真實數據的分佈，並產生讓判別器無法分辨真偽的新樣本。"
            },
            
            {
                category: "",
                question: "",
                options: ["","","",""],
                correct: 0,
                explanation: ""
            },
        ];

        let state = {
            currentIndex: 0,
            score: 0,
            userAnswers: [],
            sessionQuestions: [],
            manageCategory: categories[0],
            isAnswered: false,
            selectedIdx: null
        };

        window.onload = () => renderHome();

        function getDaysRemaining() {
            const now = new Date();
            const diffTime = EXAM_DATE - now;
            const diffDays = Math.ceil(diffTime / (1000 * 60 * 60 * 24));
            return diffDays > 0 ? diffDays : 0;
        }
        
        // 工具：洗牌
        function shuffleArray(array){
            for(let i = array.length - 1; i > 0; i--){
                const j = Math.floor(Math.random()*(i + 1));
                [array[i], array[j]] = [array[j], array[i]];
            }
            return array;
        }

        // 更新頂部按鈕
        function updateHeader(view) {
            const nav = document.getElementById('header-nav');
            const title = document.getElementById('main-title');
            
            if (view === 'quiz') {
                title.innerText = "測驗進行中";
                nav.innerHTML = `<button onclick="confirmExit()" class="text-xs bg-white/20 hover:bg-white/30 px-3 py-1.5 rounded-lg border border-white/20">退出</button>`;
            } else if (view === 'manage') {
                title.innerText = "題庫管理";
                nav.innerHTML = `<button onclick="renderHome()" class="text-xs bg-white/20 hover:bg-white/30 px-3 py-1.5 rounded-lg border border-white/20">回首頁</button>`;
            } 
            // else {
            //     title.innerText = "AI 應用規劃師測驗系統";
            //     nav.innerHTML = `<button onclick="renderManage()" class="text-xs bg-white/20 hover:bg-white/30 px-3 py-1.5 rounded-lg border border-white/20">管理題庫</button>`;
            // }
        }

        function confirmExit() {
            const modal = document.getElementById('custom-modal');
            document.getElementById('modal-title').innerText = "退出測驗";
            document.getElementById('modal-content').innerText = "確定要中斷測驗嗎？目前的進度將會遺失。";
            const confirmBtn = document.getElementById('modal-confirm');
            confirmBtn.innerText = "確定退出";
            modal.classList.remove('hidden');

            const close = () => modal.classList.add('hidden');
            document.getElementById('modal-cancel').onclick = close;
            confirmBtn.onclick = () => { close(); renderHome(); };
        }

    // --- 視圖：首頁 ---
        function renderHome() {
            updateHeader('home');
            const container = document.getElementById('view-container');
            const daysLeft = getDaysRemaining();

            container.innerHTML = `
                <div class="fade-in space-y-8">
                    <div class="p-4 bg-gradient-to-r from-amber-50 to-orange-50 border border-amber-200 rounded-2xl flex items-center justify-between shadow-sm pulse-soft">
                        <div class="flex items-center gap-3">
                            <div class="bg-amber-100 p-2 rounded-lg text-amber-600">
                                <svg xmlns="http://www.w3.org/2000/svg" class="h-6 w-6" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M8 7V3m8 4V3m-9 8h10M5 21h14a2 2 0 002-2V7a2 2 0 00-2-2H5a2 2 0 00-2-2v12a2 2 0 002 2z" /></svg>
                            </div>
                            <div>
                                <p class="text-sm font-medium text-amber-800">初級 AI 應用規劃師 考試倒數</p>
                                <p class="text-xs text-amber-600 font-bold tracking-wide">2026 / 03 / 21</p>
                            </div>
                        </div>
                        <div class="text-right">
                            <span class="text-2xl font-black text-amber-700">${daysLeft}</span>
                            <span class="text-xs font-bold text-amber-600 ml-0.5">DAYS</span>
                        </div>
                    </div>

                    <div class="text-center">
                        <h2 class="text-2xl font-black text-gray-800 mb-2">開始模擬測驗</h2>
                        <p class="text-gray-500 mb-6 text-sm">每次隨機抽選最多 <span class="text-indigo-600 font-bold">${MAX_QUESTIONS_PER_QUIZ}</span> 題並提供即時解析</p>
                        
                        <div class="grid grid-cols-1 sm:grid-cols-2 gap-4">
                            ${categories.map(cat => {
                                const count = questionBank.filter(q => q.category === cat).length;
                                return `
                                    <button onclick="startQuiz('${cat}')" class="p-6 bg-white border-2 border-gray-100 rounded-2xl hover:border-indigo-500 hover:bg-indigo-50 transition-all text-left group">
                                        <div class="flex justify-between items-center mb-1">
                                            <span class="text-indigo-600 font-bold">${cat}</span>
                                            <span class="text-[10px] bg-indigo-100 text-indigo-600 px-2 py-0.5 rounded-full font-bold">庫存 ${count} 題</span>
                                        </div>
                                        <p class="text-xs text-gray-400">點擊開始即時回饋測驗</p>
                                    </button>
                                `;
                            }).join('')}
                        </div>
                    </div>
                </div>
            `;
        }

        // --- 功能：測驗邏輯 ---
        function startQuiz(category) {
            const pool = questionBank.filter(q => q.category === category);
            if (pool.length === 0) {
                alert('該科目目前沒有題目。');
                return;
            }

            let shuffledPool = shuffleArray([...pool]).slice(0, MAX_QUESTIONS_PER_QUIZ);

            state.sessionQuestions = shuffledPool.map(q => {
                let meta = q.options.map((t, i) => ({ text: t, isCorrect: i === q.correct }));
                shuffleArray(meta);
                return {
                    category: q.category,
                    question: q.question,
                    options: meta.map(m => m.text),
                    correct: meta.findIndex(m => m.isCorrect),
                    explanation: q.explanation || "無詳細解析。"
                };
            });

            state.currentIndex = 0;
            state.score = 0;
            state.userAnswers = [];
            state.isAnswered = false;
            state.selectedIdx = null;
            updateHeader('quiz');
            renderQuestion();
        }

        function renderQuestion() {
            const container = document.getElementById('view-container');
            const q = state.sessionQuestions[state.currentIndex];
            const progress = ((state.currentIndex + 1) / state.sessionQuestions.length) * 100;

            container.innerHTML = `
                <div class="fade-in space-y-6">
                    <div class="flex justify-between items-end">
                        <div>
                            <span class="text-xs font-bold text-indigo-500 uppercase tracking-widest">${q.category}</span>
                            <h2 class="text-xl font-bold text-gray-800 mt-1">第 ${state.currentIndex + 1} 題</h2>
                        </div>
                        <span class="text-xs text-gray-400 font-bold">${state.currentIndex + 1} / ${state.sessionQuestions.length}</span>
                    </div>
                    
                    <div class="w-full bg-gray-100 h-2 rounded-full overflow-hidden">
                        <div class="bg-indigo-600 h-full transition-all duration-500" style="width: ${progress}%"></div>
                    </div>

                    <p class="text-lg font-medium text-gray-700 leading-relaxed min-h-[60px]">${q.question}</p>

                    <div class="grid grid-cols-1 gap-3">
                        ${q.options.map((opt, i) => {
                            let btnClass = "border-gray-100 bg-white hover:border-indigo-500 hover:bg-indigo-50";
                            let icon = `<span class="w-10 h-10 rounded-xl bg-gray-50 text-gray-400 flex items-center justify-center mr-4 font-black transition-colors group-hover:bg-indigo-600 group-hover:text-white">${String.fromCharCode(65 + i)}</span>`;
                            
                            if (state.isAnswered) {
                                if (i === q.correct) {
                                    // 正確選項變綠
                                    btnClass = "border-green-500 bg-green-50";
                                    icon = `<span class="w-10 h-10 rounded-xl bg-green-500 text-white flex items-center justify-center mr-4"><svg class="w-6 h-6" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="3" d="M5 13l4 4L19 7"></path></svg></span>`;
                                } else if (i === state.selectedIdx) {
                                    // 使用者選錯變紅
                                    btnClass = "border-red-500 bg-red-50";
                                    icon = `<span class="w-10 h-10 rounded-xl bg-red-500 text-white flex items-center justify-center mr-4"><svg class="w-6 h-6" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="3" d="M6 18L18 6M6 6l12 12"></path></svg></span>`;
                                } else {
                                    btnClass = "border-gray-100 bg-gray-50 opacity-60";
                                    icon = `<span class="w-10 h-10 rounded-xl bg-gray-200 text-gray-400 flex items-center justify-center mr-4 font-black">${String.fromCharCode(65 + i)}</span>`;
                                }
                            }

                            return `
                                <button onclick="handleAnswer(${i})" ${state.isAnswered ? 'disabled' : ''} class="option-btn group text-left p-4 border-2 rounded-2xl transition-all flex items-center ${btnClass} shadow-sm">
                                    ${icon}
                                    <span class="text-gray-700 font-medium">${opt}</span>
                                </button>
                            `;
                        }).join('')}
                    </div>

                    <!-- 即時解析區域 -->
                    <div id="feedback-area" class="${state.isAnswered ? 'block' : 'hidden'} fade-in space-y-4 pt-4">
                        <div class="p-5 bg-indigo-50 rounded-2xl border border-indigo-100">
                            <h4 class="font-bold text-indigo-700 mb-2 flex items-center gap-2">
                                <svg class="w-5 h-5" fill="currentColor" viewBox="0 0 20 20"><path d="M10 2a8 8 0 100 16 8 8 0 000-16zm1 11H9v-2h2v2zm0-4H9V5h2v4z"></path></svg>
                                題目解析
                            </h4>
                            <p class="text-sm text-gray-700 leading-relaxed">${q.explanation}</p>
                        </div>
                        <button onclick="nextQuestion()" class="w-full bg-indigo-600 text-white py-4 rounded-2xl font-bold hover:bg-indigo-700 transition shadow-lg shadow-indigo-200 flex items-center justify-center gap-2">
                            ${state.currentIndex < state.sessionQuestions.length - 1 ? '下一題' : '查看最終結果'}
                            <svg class="w-5 h-5" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M14 5l7 7m0 0l-7 7m7-7H3"></path></svg>
                        </button>
                    </div>
                </div>
            `;
        }

        function handleAnswer(idx) {
            if (state.isAnswered) return;
            
            state.isAnswered = true;
            state.selectedIdx = idx;
            state.userAnswers.push(idx);
            
            const q = state.sessionQuestions[state.currentIndex];
            if (idx === q.correct) {
                state.score++;
            }
            
            renderQuestion(); // 重新渲染以顯示回饋
        }

        function nextQuestion() {
            if (state.currentIndex < state.sessionQuestions.length - 1) {
                state.currentIndex++;
                state.isAnswered = false;
                state.selectedIdx = null;
                renderQuestion();
            } else {
                renderResult();
            }
        }

        function renderResult() {
            updateHeader('home');
            const container = document.getElementById('view-container');
            const total = state.sessionQuestions.length;
            const score = Math.round((state.score / total) * 100);
            
            container.innerHTML = `
                <div class="fade-in space-y-10 py-6 text-center">
                    <div>
                        <p class="text-xs font-bold text-gray-400 uppercase tracking-widest mb-2">Quiz Result</p>
                        <h2 class="text-8xl font-black text-indigo-600">${score}</h2>
                        <p class="text-gray-500 font-medium mt-2">答對 ${state.score} 題 / 共 ${total} 題</p>
                    </div>

                    <div class="bg-gray-50 p-6 rounded-3xl border border-gray-100 text-left">
                        <h3 class="font-bold text-gray-800 mb-4 flex items-center gap-2">
                            <span class="w-1.5 h-6 bg-indigo-600 rounded-full"></span>
                            表現評價
                        </h3>
                        <p class="text-gray-600 leading-relaxed">
                            ${score === 100 ? '非常優秀！您已經完全掌握了此科目的核心知識點。' :
                              score >= 70 ? '很好！您已掌握iPAS考試通過標準。' : 
                              score >= 60 ? '表現不錯！建議針對答錯的部分再進行加強。' :
                              score >= 40 ? '需要更多練習才能提升理解度，繼續加油！' : 
                              '還需要多加努力！'}
                        </p>
                    </div>

                    <div class="flex flex-col sm:flex-row gap-4">
                        <button onclick="renderHome()" class="flex-1 bg-indigo-600 text-white py-4 rounded-2xl font-bold hover:bg-indigo-700 transition shadow-lg shadow-indigo-100">
                            回到科目選擇
                        </button>
                    </div>
                </div>
            `;
        }
        
        // --- 視圖：題庫管理 ---
        function renderManage() {
            updateHeader('manage');
            const container = document.getElementById('view-container');
            const filteredQuestions = questionBank.filter(q => q.category === state.manageCategory);

            container.innerHTML = `
                <div class="fade-in space-y-6">
                    <div class="flex border-b border-gray-200">
                        ${categories.map(cat => `
                            <button onclick="switchManageTab('${cat}')" class="flex-1 py-3 font-bold transition-all ${state.manageCategory === cat ? 'tab-active' : 'text-gray-400 hover:text-gray-600'}">
                                ${cat}
                            </button>
                        `).join('')}
                    </div>

                    <div class="bg-gray-50 p-5 rounded-2xl border border-gray-200 space-y-4">
                        <h3 class="font-bold text-gray-700">新增題目到「${state.manageCategory}」</h3>
                        <input id="new-q-text" type="text" placeholder="題目內容" class="w-full p-3 border rounded-xl outline-none focus:ring-2 focus:ring-indigo-500 border-gray-300">
                        <div class="grid grid-cols-1 md:grid-cols-2 gap-3">
                            <input id="opt-0" type="text" placeholder="選項 A" class="p-2 border rounded-lg border-gray-300">
                            <input id="opt-1" type="text" placeholder="選項 B" class="p-2 border rounded-lg border-gray-300">
                            <input id="opt-2" type="text" placeholder="選項 C" class="p-2 border rounded-lg border-gray-300">
                            <input id="opt-3" type="text" placeholder="選項 D" class="p-2 border rounded-lg border-gray-300">
                        </div>
                        <div class="flex flex-wrap items-center gap-4">
                            <select id="correct-idx" class="p-2 border rounded-lg border-gray-300 text-sm">
                                <option value="0">正確答案：A</option>
                                <option value="1">正確答案：B</option>
                                <option value="2">正確答案：C</option>
                                <option value="3">正確答案：D</option>
                            </select>
                            <button onclick="addQuestion()" class="flex-1 bg-green-600 text-white py-2 rounded-xl font-bold hover:bg-green-700 transition shadow-md">加入題庫</button>
                        </div>
                        <textarea id="new-q-exp" placeholder="請輸入本題詳細解析內容..." class="w-full p-3 border rounded-lg border-gray-300 text-sm h-24 outline-none focus:ring-2 focus:ring-indigo-500"></textarea>
                    </div>

                    <div class="space-y-3">
                        <h3 class="font-bold text-gray-700 px-1">現有題目 (${filteredQuestions.length})</h3>
                        <div class="max-h-[250px] overflow-y-auto space-y-2 pr-2">
                            ${filteredQuestions.length === 0 ? '<p class="text-center text-gray-400 py-8 italic">此科目尚無題目</p>' : 
                                filteredQuestions.map((q, idx) => {
                                    const originalIdx = questionBank.findIndex(item => item === q);
                                    return `
                                        <div class="bg-white p-4 border border-gray-100 rounded-xl flex justify-between items-start hover:shadow-sm transition">
                                            <div class="flex-1 pr-4 text-sm">
                                                <p class="font-bold text-gray-800 leading-relaxed">${idx + 1}. ${q.question}</p>
                                                <p class="text-indigo-500 mt-2 font-medium">正確答案：${q.options[q.correct]}</p>
                                            </div>
                                            <button onclick="deleteQuestion(${originalIdx})" class="text-gray-300 hover:text-red-500 transition p-1">
                                                <svg xmlns="http://www.w3.org/2000/svg" class="h-5 w-5" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                                                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 7l-.867 12.142A2 2 0 0116.138 21H7.862a2 2 0 01-1.995-1.858L5 7m5 4v6m4-6v6m1-10V4a1 1 0 00-1-1h-4a1 1 0 00-1 1v3M4 7h16" />
                                                </svg>
                                            </button>
                                        </div>
                                    `;
                                }).join('')
                            }
                        </div>
                    </div>
                </div>
            `;
        }

        function switchManageTab(cat){
            state.manageCategory = cat;
            renderManage();
        }

        function addQuestion() {
            const q = document.getElementById('new-q-text').value.trim();
            const exp = document.getElementById('new-q-exp').value.trim();
            const opts = [
                document.getElementById('opt-0').value.trim(),
                document.getElementById('opt-1').value.trim(),
                document.getElementById('opt-2').value.trim(),
                document.getElementById('opt-3').value.trim()
            ];
            const correct = parseInt(document.getElementById('correct-idx').value);

            if (!q || opts.some(o => !o)) {
                alert('請填寫完整題目與四個選項內容');
                return;
            }

            questionBank.push({
                category: state.manageCategory,
                question: q,
                options: opts,
                correct: correct,
                explanation: exp || "無詳細解析。"
            });

            renderManage();
        }

        function deleteQuestion(originalIndex) {
            const modal = document.getElementById('custom-modal');
            document.getElementById('modal-title').innerText = "確認刪除題目";
            document.getElementById('modal-content').innerText = "題目一旦刪除將無法復原，確定要執行嗎？";
            const confirmBtn = document.getElementById('modal-confirm');
            confirmBtn.innerText = "確定刪除";
            modal.classList.remove('hidden');

            const close = () => modal.classList.add('hidden');
            document.getElementById('modal-cancel').onclick = close;
            confirmBtn.onclick = () => { 
                questionBank.splice(originalIndex, 1);
                renderManage();
                close(); 
            };
        }
    </script>
</body>
</html>
